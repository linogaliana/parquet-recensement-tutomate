[
  {
    "objectID": "tuto/r.html",
    "href": "tuto/r.html",
    "title": "Utilisation du format Parquet avec  illustrÃ© Ã  partir de quelques exemples",
    "section": "",
    "text": "Ce tutoriel vise Ã  offrir une approche complÃ©mentaire au guide dâ€™utilisation des donnÃ©es du recensement au format Parquet publiÃ© sur https://ssphub.netlify.app pour accompagner la diffusion de celles-ci par lâ€™Insee.\nIl sâ€™agit dâ€™un tutoriel prÃ©parÃ© pour lâ€™atelier tuto@mate Ã  lâ€™EHESS le 5 novembre 2024. Ce tutoriel est exclusivement en R. Les slides de la prÃ©sentation sont disponibles ci-dessous:\nIl propose des exemples variÃ©s pour illustrer la simplicitÃ© dâ€™usage du format Parquet. Parmi ceux-ci, Ã  partir du recensement de la population:\nA partir de la base permanent des Ã©quipements (BPE):"
  },
  {
    "objectID": "tuto/r.html#requÃªtes-sur-les-colonnes-select",
    "href": "tuto/r.html#requÃªtes-sur-les-colonnes-select",
    "title": "Utilisation du format Parquet avec  illustrÃ© Ã  partir de quelques exemples",
    "section": "RequÃªtes sur les colonnes (SELECT)",
    "text": "RequÃªtes sur les colonnes (SELECT)\nLâ€™une des forces du format Parquet est de simplifier lâ€™import de fichiers volumineux qui ne comportent que quelques colonnes nous intÃ©ressant. Par exemple, la table des individus comporte 88 colonnes, il est peu probable quâ€™une seule analyse sâ€™intÃ©resse Ã  toutes celles-ci (ou elle risque dâ€™Ãªtre fort indigeste).\n\nComme cela est illustrÃ© dans TipÂ 1, la diffÃ©rence de volumÃ©trie entre un fichier non filtrÃ© et un fichier filtrÃ© est importante.\n\n\nDuckDB via tidyverse\nDuckDB exclusivement\n\n\n\n\ntable_individu %&gt;%\n  select(poids = IPONDI, AGED, VOIT) %&gt;%\n  head(5) %&gt;%\n  collect()\n\n\n  \n\n\n\n\n\n\nglue(\n  \"SELECT IPONDI AS poids, AGED, VOIT \",\n  \"FROM read_parquet(\\\"{filename_table_individu}\\\") \"\n)\n\nSELECT IPONDI AS poids, AGED, VOIT FROM read_parquet(\"data/RPindividus.parquet\") \n\n\n\nquery &lt;- glue(\n  \"SELECT IPONDI AS poids, AGED, VOIT \",\n  \"FROM read_parquet(\\\"{filename_table_individu}\\\") \"\n)\ndbGetQuery(\n  con,\n  query %&gt;% head(10)\n)\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nTipÂ 1: Comprendre lâ€™optimisation permise par Parquet et DuckDB\n\n\n\n\n\nPour rÃ©duire la volumÃ©trie des donnÃ©es importÃ©es, il est possible de mettre en oeuvre deux stratÃ©gies:\n\nNâ€™importer quâ€™un nombre limitÃ© de colonnes\nNâ€™importer quâ€™un nombre limitÃ© de lignes\n\nComme cela a Ã©tÃ© Ã©voquÃ© dans les slides, le format Parquet est particuliÃ¨rement optimisÃ© pour le premier besoin. Câ€™est donc gÃ©nÃ©ralement la premiÃ¨re optimisation mise en oeuvre. Pour sâ€™en convaincre on peut regarder la taille des donnÃ©es importÃ©es dans deux cas:\n\nOn utilise beaucoup de lignes mais peu de colonnes\nOn utilise beaucoup de colonnes mais peu de lignes\n\nPour cela, nous utilisons la fonction SQL EXPLAIN ANALYZE disponible dans duckdb. Elle dÃ©compose le plan dâ€™exÃ©cution de duckdb, ce qui nous permettra de comprendre la stratÃ©gie dâ€™optimisation. Elle permet aussi de connaÃ®tre le volume de donnÃ©es importÃ©es lorsquâ€™on rÃ©cupÃ¨re un fichier dâ€™internet. En effet, duckdb est malin: plutÃ´t que de tÃ©lÃ©charger un fichier entier pour nâ€™en lire quâ€™une partie, la librairie est capable de nâ€™importer que les blocs du fichier qui lâ€™intÃ©resse.\nCeci nÃ©cessite lâ€™utilisation de lâ€™extension httpfs (un peu lâ€™Ã©quivalent des library de R en duckdb). Elle sâ€™installe et sâ€™utilise de la maniÃ¨re suivante\n\ndbExecute(\n  con,\n  glue(\n    \"INSTALL httpfs;\",\n    \"LOAD httpfs;\"\n  )\n)\n\nDemandons Ã  DuckDB dâ€™exÃ©cuter la requÃªte â€œbeaucoup de colonnes, pas beaucoup de lignesâ€ et regardons le plan dâ€™exÃ©cution et les informations donnÃ©es par DuckDB:\n\nVoir le plan : â€œbeaucoup de colonnes, pas beaucoup de lignesâ€\n\nglue(  \n    'EXPLAIN ANALYZE ',\n    'SELECT * FROM read_parquet(\"{url_bpe}\") LIMIT 5'\n  )\n\nEXPLAIN ANALYZE SELECT * FROM read_parquet(\"https://minio.lab.sspcloud.fr/lgaliana/diffusion/BPE23.parquet\") LIMIT 5\n\n\n\nplan &lt;- dbGetQuery(\n  con,\n  glue(  \n    'EXPLAIN ANALYZE ',\n    'SELECT * FROM read_parquet(\"{url_bpe}\") LIMIT 5'\n  )\n)\n\n\nprint(plan)\n\nanalyzed_plan\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚    Query Profiling Information    â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nEXPLAIN ANALYZE SELECT * FROM read_parquet(\"https://minio.lab.sspcloud.fr/lgaliana/diffusion/BPE23.parquet\") LIMIT 5\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚            HTTP Stats:            â”‚â”‚\nâ”‚â”‚                                   â”‚â”‚\nâ”‚â”‚           in: 164.5 MiB           â”‚â”‚\nâ”‚â”‚            out: 0 bytes           â”‚â”‚\nâ”‚â”‚              #HEAD: 1             â”‚â”‚\nâ”‚â”‚              #GET: 5              â”‚â”‚\nâ”‚â”‚              #PUT: 0              â”‚â”‚\nâ”‚â”‚              #POST: 0             â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚         Total Time: 12.09s        â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      RESULT_COLLECTOR     â”‚\nâ”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚\nâ”‚             0             â”‚\nâ”‚          (0.00s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             \nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      EXPLAIN_ANALYZE      â”‚\nâ”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚\nâ”‚             0             â”‚\nâ”‚          (0.00s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             \nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚           LIMIT           â”‚\nâ”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚\nâ”‚             5             â”‚\nâ”‚          (0.00s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             \nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚       READ_PARQUET        â”‚\nâ”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚\nâ”‚             AN            â”‚\nâ”‚           NOMRS           â”‚\nâ”‚           CNOMRS          â”‚\nâ”‚          NUMVOIE          â”‚\nâ”‚           INDREP          â”‚\nâ”‚          TYPVOIE          â”‚\nâ”‚          LIBVOIE          â”‚\nâ”‚            CADR           â”‚\nâ”‚           CODPOS          â”‚\nâ”‚           DEPCOM          â”‚\nâ”‚            DEP            â”‚\nâ”‚            REG            â”‚\nâ”‚            DOM            â”‚\nâ”‚            SDOM           â”‚\nâ”‚           TYPEQU          â”‚\nâ”‚           SIRET           â”‚\nâ”‚      STATUT_DIFFUSION     â”‚\nâ”‚          CANTINE          â”‚\nâ”‚          INTERNAT         â”‚\nâ”‚            RPI            â”‚\nâ”‚             EP            â”‚\nâ”‚           CL_PGE          â”‚\nâ”‚            SECT           â”‚\nâ”‚    ACCES_AIRE_PRATIQUE    â”‚\nâ”‚        ACCES_LIBRE        â”‚\nâ”‚      ACCES_SANITAIRE      â”‚\nâ”‚      ACCES_VESTIAIRE      â”‚\nâ”‚     CAPACITE_D_ACCUEIL    â”‚\nâ”‚        PRES_DOUCHE        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             \n\n\n\nVoir le plan : â€œpeu de colonnes, beaucoup de lignesâ€\n\nplan &lt;- dbGetQuery(\n  con,\n  glue(  \n    'EXPLAIN ANALYZE ',\n    'SELECT TYPEQU, LONGITUDE, LATITUDE FROM read_parquet(\"{url_bpe}\") LIMIT 10000'\n  )\n)\n\n\nprint(plan)\n\nanalyzed_plan\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚    Query Profiling Information    â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nEXPLAIN ANALYZE SELECT TYPEQU, LONGITUDE, LATITUDE FROM read_parquet(\"https://minio.lab.sspcloud.fr/lgaliana/diffusion/BPE23.parquet\") LIMIT 10000\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚            HTTP Stats:            â”‚â”‚\nâ”‚â”‚                                   â”‚â”‚\nâ”‚â”‚            in: 38.5 MiB           â”‚â”‚\nâ”‚â”‚            out: 0 bytes           â”‚â”‚\nâ”‚â”‚              #HEAD: 1             â”‚â”‚\nâ”‚â”‚              #GET: 8              â”‚â”‚\nâ”‚â”‚              #PUT: 0              â”‚â”‚\nâ”‚â”‚              #POST: 0             â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚         Total Time: 2.38s         â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      RESULT_COLLECTOR     â”‚\nâ”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚\nâ”‚             0             â”‚\nâ”‚          (0.00s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             \nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      EXPLAIN_ANALYZE      â”‚\nâ”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚\nâ”‚             0             â”‚\nâ”‚          (0.00s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             \nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚           LIMIT           â”‚\nâ”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚\nâ”‚           10000           â”‚\nâ”‚          (0.00s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             \nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚       READ_PARQUET        â”‚\nâ”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚\nâ”‚           TYPEQU          â”‚\nâ”‚         LONGITUDE         â”‚\nâ”‚          LATITUDE         â”‚\nâ”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚\nâ”‚        EC: 2773420        â”‚\nâ”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚\nâ”‚           30720           â”‚\nâ”‚          (5.63s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             \n\n\nLa comparaison de ces plans dâ€™exÃ©cution montre lâ€™intÃ©rÃªt de faire un filtre sur les colonnes : les besoins computationnels sont drastiquement diminuÃ©s. Le filtre sur les lignes nâ€™arrive que dans un second temps, une fois les colonnes sÃ©lectionnÃ©es.\nPourquoi seulement un rapport de 1 Ã  4 entre le poids des deux fichiers ? Câ€™est parce que nos requÃªtes comportent toute deux la variable IPONDI (les poids Ã  utiliser pour extrapoler lâ€™Ã©chantillon Ã  la population) qui est Ã  haute prÃ©cision lÃ  oÃ¹ beaucoup dâ€™autres colonnes comportent un nombre rÃ©duit de modalitÃ©s et sont donc peu volumineuses.\n\n\n\nDuckDB propose Ã©galement des fonctionnalitÃ©s pour extraire des colonnes Ã  travers des expressions rÃ©guliÃ¨res. Cette approche est Ã©galement possible avec le tidyverse\n\n\nDuckDB via tidyverse\nDuckDB exclusivement\n\n\n\n\ntable_individu %&gt;%\n  select(poids = IPONDI, contains(\"AGE\")) %&gt;%\n  head(10)\n\n\n  \n\n\n\n\n\n\ndbGetQuery(\n  con,\n  glue(\n    \"FROM read_parquet(\\\"{filename_table_individu}\\\") \",\n    \"SELECT IPONDI AS poids, COLUMNS('.*AGE.*') \",\n    \"LIMIT 10\"\n  )\n)"
  },
  {
    "objectID": "tuto/r.html#requÃªtes-sur-les-lignes-where",
    "href": "tuto/r.html#requÃªtes-sur-les-lignes-where",
    "title": "Utilisation du format Parquet avec  illustrÃ© Ã  partir de quelques exemples",
    "section": "RequÃªtes sur les lignes (WHERE)",
    "text": "RequÃªtes sur les lignes (WHERE)\n\n\nDuckDB via tidyverse\nDuckDB exclusivement\n\n\n\n\ntable_individu %&gt;%\n  filter(DEPT %in% c(\"11\", \"31\", \"34\")) %&gt;%\n  head(10)\n\n\n  \n\n\n\n\n\n\ndbGetQuery(\n  con,\n  glue(\n    \"FROM read_parquet(\\\"{filename_table_individu}\\\") \",\n    \"SELECT IPONDI, AGED, DEPT \",\n    \"WHERE DEPT IN ('11', '31', '34') \",\n    \"LIMIT 10\")\n)\n\n\n  \n\n\n\n\n\n\nLes filtres sur les observations peuvent Ãªtre faits Ã  partir de critÃ¨res sur plusieurs colonnes. Par exemple, pour ne conserver que les observations de la ville de Nice oÃ¹ la date dâ€™emmÃ©nagement est postÃ©rieure Ã  2020, la requÃªte suivante peut Ãªtre utilisÃ©e :\n\n\nDuckDB via tidyverse\nDuckDB exclusivement\n\n\n\n\n\n\nListingÂ 1: Ne conserver que les NiÃ§ois qui ont emmÃ©nagÃ© depuis 2021\n\ntable_logement %&gt;% filter(COMMUNE == \"06088\", AEMM &gt; 2020) %&gt;% collect() %&gt;% nrow(.)\n\n\n\n\n[1] 2692\n\n\n\n\n\ndbGetQuery(\n  con,\n  glue(\n    \"FROM read_parquet(\\\"{filename_table_logement}\\\") \",\n    \"SELECT * \",\n    \"WHERE COMMUNE = '06088' and AEMM &gt; 2020 \",\n    \"LIMIT 10\"\n  )\n)"
  },
  {
    "objectID": "tuto/r.html#exemples-sans-groupes",
    "href": "tuto/r.html#exemples-sans-groupes",
    "title": "Utilisation du format Parquet avec  illustrÃ© Ã  partir de quelques exemples",
    "section": "Exemples sans groupes",
    "text": "Exemples sans groupes\nLa fonction DISTINCT appliquÃ©e Ã  la variable ARM permet dâ€™extraire la liste des codes arrondissements prÃ©sents dans la base de donnÃ©es.\n\n\nDuckDB via tidyverse\nDuckDB exclusivement\n\n\n\n\ntable_logement %&gt;%\n  filter(str_detect(ARM, \"ZZZZZ\", negate = TRUE)) %&gt;%\n  summarise(ARM = distinct(ARM)) %&gt;%\n  arrange(ARM)\n\n\n  \n\n\n\n\n\n\nquery &lt;- glue_sql(\n    \"FROM read_parquet({filename_table_logement}) \",\n    \"SELECT DISTINCT(ARM) \",\n    \"WHERE NOT CONTAINS(ARM, 'ZZZZZ') \",\n    \"ORDER BY ARM\",\n    .con=con\n)\npaste(dbGetQuery(con, query)$ARM, collapse = \", \")\n\n[1] \"13201, 13202, 13203, 13204, 13205, 13206, 13207, 13208, 13209, 13210, 13211, 13212, 13213, 13214, 13215, 13216, 69381, 69382, 69383, 69384, 69385, 69386, 69387, 69388, 69389, 75101, 75102, 75103, 75104, 75105, 75106, 75107, 75108, 75109, 75110, 75111, 75112, 75113, 75114, 75115, 75116, 75117, 75118, 75119, 75120\"\n\n\n\n\n\nIl est possible dâ€™extraire des statistiques beaucoup plus raffinÃ©es par le biais dâ€™une requÃªte SQL plus complexe. Par exemple pour calculer le nombre dâ€™habitants de Toulouse qui ont changÃ© de logement en un an:\n\n\nDuckDB via tidyverse\nDuckDB exclusivement\n\n\n\n\n\n\nListingÂ 2: Nombre de Toulousains qui ont changÃ© de logement en un an\n\ntable_logement %&gt;%\n  filter(COMMUNE == '31555', !IRANM %in% c('1', 'Z'), INPER != \"Y\") %&gt;%\n  mutate(INPER = as.integer(INPER)) %&gt;%\n  summarise(habitants_toulouse_demenagement = as.integer(sum(IPONDL * INPER)))\n\n\n\n\nWarning: Missing values are always removed in SQL aggregation functions.\nUse `na.rm = TRUE` to silence this warning\nThis warning is displayed once every 8 hours.\n\n\n\n  \n\n\n\n\n\n\nquery &lt;- glue(\n  \"FROM read_parquet(\\\"{filename_table_logement}\\\") \",\n  \"SELECT CAST(SUM(IPONDL*CAST(INPER AS INT)) AS INT) \",\n  \"AS habitants_toulouse_demenagement \",\n  \"WHERE COMMUNE == '31555' AND IRANM NOT IN ('1', 'Z') AND INPER != 'Y'\"\n)\ndbGetQuery(con, query)"
  },
  {
    "objectID": "tuto/r.html#statistiques-par-groupe",
    "href": "tuto/r.html#statistiques-par-groupe",
    "title": "Utilisation du format Parquet avec  illustrÃ© Ã  partir de quelques exemples",
    "section": "Statistiques par groupe",
    "text": "Statistiques par groupe\nSQL et dplyr permettent dâ€™aller loin dans la finesse des statistiques descriptives mises en oeuvre. Cela sera illustrÃ© Ã  lâ€™aide de plusieurs exemples rÃ©flÃ©tant des statistiques pouvant Ãªtre construites grÃ¢ce Ã  ces donnÃ©es dÃ©taillÃ©es.\nExemple 1: pyramide des Ã¢ges dans lâ€™Aude, lâ€™HÃ©rault et le Gard\nLe premier exemple est un comptage sur trois dÃ©partements. Il illustre la dÃ©marche suivante:\n\nOn se restreint aux observations dâ€™intÃ©rÃªt (ici 3 dÃ©partements)\nOn applique la fonction summarise pour calculer une statistique par groupe, en lâ€™occurrence la somme des pondÃ©rations\nOn retravaille les donnÃ©es\n\nEnsuite, une fois que nos donnÃ©es sont rÃ©cupÃ©rÃ©es dans R, on peut faire la figure avec ggplot\n\n\n\nListingÂ 3: Pyramide des Ã¢ges dans lâ€™Aude, lâ€™HÃ©rault et le Gard\n\npyramide_ages &lt;- table_individu %&gt;%\n  filter(DEPT %in% c('11', '31', '34')) %&gt;%\n  group_by(AGED, departement = DEPT) %&gt;%\n  summarise(individus = sum(IPONDI), .groups = \"drop\") %&gt;%\n  arrange(departement, AGED) %&gt;%\n  collect()\n\n\nggplot(pyramide_ages, aes(x = AGED, y = individus)) +\n  geom_bar(aes(fill = departement), stat = \"identity\") +\n  geom_vline(xintercept = 18, color = \"grey\", linetype = \"dashed\") +\n  facet_wrap(~departement, scales = \"free_y\", nrow = 3) +\n  theme_minimal() +\n  labs(y = \"Individus recensÃ©s\", x = \"Ã‚ge\")\n\n\n\n\n\n\n\n\n\n\nExemple 2: rÃ©partition des plus de 60 ans par dÃ©partement\nLâ€™objectif de ce deuxiÃ¨me exemple est dâ€™illustrer la construction dâ€™une statistique un peu plus complexe et la maniÃ¨re de projeter celle-ci sur une carte.\nPour avoir la rÃ©partition des plus de 60 ans par dÃ©partement, quelques lignes de dplyr suffisent:\n\n\n\nListingÂ 4: Calculer la part des plus de 60 ans dans la population de chaque dÃ©partement\n\npart_population_60_plus &lt;- table_individu %&gt;%\n  group_by(DEPT) %&gt;%\n  summarise(\n    total_population = sum(IPONDI), # Population totale\n    population_60_plus = sum(IPONDI[AGED &gt; 60]) # Population de plus de 60 ans\n  ) %&gt;%\n  mutate(pourcentage_60_plus = population_60_plus / total_population * 100) %&gt;%\n  collect()\n\npart_population_60_plus\n\n\n\n\n\n  \n\n\n\nIl ne reste plus quâ€™Ã  projeter ceci sur une carte. Pour cela, un join Ã  notre fond de carte suffit. Comme les donnÃ©es sont agrÃ©gÃ©es et dÃ©jÃ  dans R, il nâ€™y a rien de spÃ©cifique Ã  duckdb ici.\n\nAssociation de part_population_60_plus au fond de carte des dÃ©partements# Joindre les donnÃ©es au fond de carte des dÃ©partements\ndepartements_60_plus_sf &lt;- departements %&gt;%\n  inner_join(\n    part_population_60_plus,\n    by = c(\"INSEE_DEP\" = \"DEPT\")\n  )\n\n\nFinalement, il ne reste plus quâ€™Ã  produire la carte:\n\nggplot(departements_60_plus_sf) +\n    geom_sf(aes(fill = pourcentage_60_plus)) + \n    scale_fill_fermenter(n.breaks = 5, palette = \"PuBuGn\", direction = 1) + \n    theme_void() + \n    labs(\n        title = \"Part des personnes de plus de 60 ans par dÃ©partement\",\n        caption = \"Source: Insee, Fichiers dÃ©tails du recensement de la population\",\n        fill = \"Part (%)\"\n    )\n\n\n\n\n\n\n\nSi on prÃ©fÃ¨re reprÃ©senter ceci sous forme de tableau, on peut utiliser le package gt.\n\nCode pour avoir le classement des dÃ©partements pour lesquels la population de plus de 60 ans est la plus importantetop_population &lt;- part_population_60_plus %&gt;%\n  left_join(\n    departements %&gt;% select(INSEE_DEP, LIBELLE_DEPARTEMENT ) %&gt;% st_set_geometry(NULL),\n    by = c(\"DEPT\" = \"INSEE_DEP\")\n  ) %&gt;%\n  mutate(departement = paste0(LIBELLE_DEPARTEMENT, \" (\", DEPT , \")\")) %&gt;%\n  select(-DEPT, -LIBELLE_DEPARTEMENT) %&gt;%\n  arrange(desc(pourcentage_60_plus)) %&gt;%\n  select(DEPT = departement, everything()) %&gt;%\n  head(10)\n\ngt(\n  top_population\n) %&gt;%\n  gt_plt_bar_pct(\n    column = pourcentage_60_plus,\n    scaled = TRUE,\n    labels = TRUE\n  ) %&gt;%\n    fmt_number(\n    columns = c(\"total_population\", \"population_60_plus\"),\n    decimals = 0,\n    sep_mark = \" \"\n  ) %&gt;%\n  fmt_number(\n      columns = c(\"pourcentage_60_plus\"),\n      decimals = 1\n    ) %&gt;%\n  cols_label(\n    DEPT = md(\"**DÃ©partement**\"),\n    total_population = md(\"**Population**\"),\n    population_60_plus = md(\"**Population de plus de 60 ans**\"),\n    pourcentage_60_plus = md(\"*Part (%)*\")\n  )\n\n\n\n\n\nDÃ©partement\nPopulation\nPopulation de plus de 60 ans\nPart (%)\n\n\n\nCreuse (23)\n116 178\n45 561\n\n\n39.2%\n\n\n\n\nLot (46)\n174 397\n67 122\n\n\n38.5%\n\n\n\n\nNiÃ¨vre (58)\n202 728\n76 108\n\n\n37.5%\n\n\n\n\nDordogne (24)\n413 180\n153 405\n\n\n37.1%\n\n\n\n\nCantal (15)\n144 321\n51 594\n\n\n35.7%\n\n\n\n\nGers (32)\n191 737\n68 261\n\n\n35.6%\n\n\n\n\nIndre (36)\n218 469\n77 537\n\n\n35.5%\n\n\n\n\nCharente-Maritime (17)\n655 648\n232 006\n\n\n35.4%\n\n\n\n\nAllier (03)\n335 380\n118 481\n\n\n35.3%\n\n\n\n\nCorrÃ¨ze (19)\n239 286\n84 511\n\n\n35.3%\n\n\n\n\n\n\n\n\nExemple 3: part des rÃ©sidences secondaires et des logements vacants\nIl est tout Ã  fait possible de faire des Ã©tapes antÃ©rieures de prÃ©paration de donnÃ©es, notamment de crÃ©ation de variables avec mutate.\nLâ€™exemple suivant illustre la prÃ©paration de donnÃ©es avant la construction de statistiques descriptives de la maniÃ¨re suivante:\n\nCrÃ©ation dâ€™une variable de dÃ©partement Ã  partir du code commune\nDÃ©compte des logements par dÃ©partement\n\n\n\n\nListingÂ 5: Part des logements vacants et rÃ©sidences secondaires dans le parc de logement\n\n#| output: false\nparc_locatif &lt;- table_logement %&gt;%\n  mutate(DEPT = substring(COMMUNE, 1, 3)) %&gt;%\n  mutate(\n    DEPT = if_else(\n      starts_with(DEPT, \"97\"),\n      DEPT,\n      substring(DEPT, 1, 2)\n    )\n  ) %&gt;%\n  group_by(DEPT, CATL) %&gt;%\n  summarise(n = sum(IPONDL)) %&gt;%\n  ungroup() %&gt;%\n  collect()\n\n\n\n\n`summarise()` has grouped output by \"DEPT\". You can override using the\n`.groups` argument.\n\n\n\n# Jointure avec le fond de carte des dÃ©partements\nparc_locatif_sf &lt;- departements %&gt;%\n  inner_join(\n    parc_locatif,\n    by = c(\"INSEE_DEP\" = \"DEPT\"),\n    relationship = \"many-to-many\"\n  ) %&gt;%\n  group_by(INSEE_DEP) %&gt;%\n  mutate(p = n/sum(n)) %&gt;%\n  ungroup\n\n\n1\n\nOn a des clÃ©s dupliquÃ©es dans le fond cartiflette (le zoom pour lâ€™Ile de France) et dans le dataframe (4 valeurs par dep)\n\n\n\n\nCode pour produire la carte# Carte: Part des rÃ©sidences secondaires\ncarte1 &lt;- ggplot(parc_locatif_sf %&gt;% filter(CATL == \"3\")) +\n  geom_sf(aes(fill = p), color = \"white\") +\n  scale_fill_fermenter(\n    n.breaks = 5, \n    palette = \"RdPu\",\n    direction = 1,\n    labels = scales::label_percent(\n      scale_cut = scales::cut_short_scale()\n    )\n  ) +\n  theme_void() +\n  labs(\n    fill = \"Part dans le\\nparc de logement (%)\",\n    title = \"Cartographie des rÃ©sidences secondaires\",\n    caption = \"Source: Insee, Fichiers dÃ©tails du recensement de la population\"\n  )\n\n# Carte: Part des logements vacants\ncarte2 &lt;- ggplot(parc_locatif_sf %&gt;% filter(CATL == \"4\")) +\n  geom_sf(aes(fill = p), color = \"white\") +\n  scale_fill_fermenter(\n    n.breaks = 5, \n    palette = \"RdPu\",\n    direction = 1,\n    labels = scales::label_percent(\n      scale_cut = scales::cut_short_scale()\n    )\n  ) +\n  theme_void() +\n  labs(\n    fill = \"Part dans le\\nparc de logement (%)\",\n    title = \"Cartographie des logements vacants\",\n    caption = \"Source: Insee, Fichiers dÃ©tails du recensement de la population\"\n  )\n\n\ncarte1\ncarte2\n\n\n\n\n\nRÃ©sidences secondaires\n\n\n\n\n\nLogements vacants"
  },
  {
    "objectID": "tuto/r.html#footnotes",
    "href": "tuto/r.html#footnotes",
    "title": "Utilisation du format Parquet avec  illustrÃ© Ã  partir de quelques exemples",
    "section": "Footnotes",
    "text": "Footnotes\n\nSi vous avez clÃ´nÃ© le dÃ©pÃ´t disponible sur Github R, un environnement virtuel renv vous permet de recrÃ©er la mÃªme configuration logicielle que celle utilisÃ©e pour gÃ©nÃ©rer cette page. Pour cela, il suffit de faire renv::restore().â†©ï¸\nPour en savoir plus sur ce projet, se rendre sur la documentation du projet.â†©ï¸\nCe filtre est construit aprÃ¨s lecture du dictionnaire des variables de la BPE.â†©ï¸"
  },
  {
    "objectID": "slides/index.html#plan",
    "href": "slides/index.html#plan",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Plan",
    "text": "Plan\n\nContexte\nPourquoi le format Parquet ?\nLâ€™Ã©cosystÃ¨me Parquet\nDÃ©monstration"
  },
  {
    "objectID": "slides/index.html#le-recensement-de-la-population",
    "href": "slides/index.html#le-recensement-de-la-population",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Le recensement de la population",
    "text": "Le recensement de la population\n\nMission historique de lâ€™Insee depuis 1946\n\nLâ€™Insee organise, les communes rÃ©alisent la collecte\n\n\n\n\nUne source dâ€™utilitÃ© publique :\n\nPopulations lÃ©gales: dotations de lâ€™Ã‰tat aux communes, organisation des scrutins, Ã©quipements publics, etc.\nRecherche: caractÃ©ristiques socio-dÃ©mographiques, mobilitÃ©sâ€¦\n\n\n\n\n\n\n\n\nEnquÃªtes annuelles de recensement (EAR) depuis 2004\n\n\n\nPour une commune de moins de 10 000 habitants:\n\nCollecte exhaustive une fois tous les 5 ans.\n\nPour une commune de plus de 10 000 habitants:\n\nChaque annÃ©e, 8% des logements sont recensÃ©s ;\nLe rÃ©sultat du recensement est calculÃ© Ã  partir des 5 derniÃ¨res annÃ©es (=40% logements)\n\n\nDocumentation technique sur le recensement"
  },
  {
    "objectID": "slides/index.html#une-diffusion-sous-plusieurs-formes",
    "href": "slides/index.html#une-diffusion-sous-plusieurs-formes",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Une diffusion sous plusieurs formes",
    "text": "Une diffusion sous plusieurs formes\n\nDiffusion sur insee.fr sous plusieurs formes:\n\nPages â€œdynamiquesâ€ sur insee.fr\nExports dâ€™agrÃ©gats depuis statistiques-locales.insee.fr/\nDes donnÃ©es, des cartes, des publications, etc..\n\n\n\n\nMais beaucoup de gestes manuels pour obtenir un seul agrÃ©gat\n\n\n\n\nUne information parfois difficile Ã  trouver sur le site de lâ€™Insee"
  },
  {
    "objectID": "slides/index.html#une-diffusion-sous-plusieurs-formes-1",
    "href": "slides/index.html#une-diffusion-sous-plusieurs-formes-1",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Une diffusion sous plusieurs formes",
    "text": "Une diffusion sous plusieurs formes\n\nLes fichiers agrÃ©gÃ©s\n\n\n\nStructure type: une ligne par commune ou IRIS\n\n\n\nTaille de chaque fichier relativement raisonnable\n\nCSV gÃ©nÃ©ralement de quelques Mo, jusquâ€™Ã  150 Mo"
  },
  {
    "objectID": "slides/index.html#une-diffusion-sous-plusieurs-formes-2",
    "href": "slides/index.html#une-diffusion-sous-plusieurs-formes-2",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Une diffusion sous plusieurs formes",
    "text": "Une diffusion sous plusieurs formes\n\nLes micro-donnÃ©es anonymisÃ©es\n\n\nStructure type: une ligne par observation\n\nUn logement, un individuâ€¦\n\n\n\n\nPermet de construire dâ€™autres croisements que ceux proposÃ©s sur insee.fr\n\n\n\n\n\n\n\n\n\nUn format destinÃ© Ã  des utilisateurs avancÃ©s\n\n\n\nUne source riche mais des prÃ©cautions dâ€™emploi Ã  respecter:\n\nPondÃ©rations Ã  prendre en compte\nInterprÃ©tation des petits effectifsâ€¦\n\nDemande une certaine expertise"
  },
  {
    "objectID": "slides/index.html#dÃ©fi",
    "href": "slides/index.html#dÃ©fi",
    "title": "Le format de donnÃ©es Parquet",
    "section": "DÃ©fi",
    "text": "DÃ©fi\n\nCe sont des fichiers trÃ¨s volumineux\n\nJusquâ€™Ã  100 variables et 25 millions de lignes\nFichier CSV jusquâ€™Ã  5 Go\n\n\n\n\nPour lâ€™Insee : complexes Ã  produire et valider avant diffusion\n\n\n\n\nPour lâ€™utilisateur.trice : complexes Ã  tÃ©lÃ©charger, stocker et exploiter"
  },
  {
    "objectID": "slides/index.html#solution-historique",
    "href": "slides/index.html#solution-historique",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Solution historique",
    "text": "Solution historique\n\nDiffusion zippÃ©e (CSV) ou format DBase (format propriÃ©taire)\n\nDÃ©coupage en fichiers par grandes zones de rÃ©gions"
  },
  {
    "objectID": "slides/index.html#une-source-idÃ©ale-pour-innover-dans-la-diffusion",
    "href": "slides/index.html#une-source-idÃ©ale-pour-innover-dans-la-diffusion",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Une source idÃ©ale pour innover dans la diffusion",
    "text": "Une source idÃ©ale pour innover dans la diffusion\n\nMontÃ©e en puissance du format Parquet pour les usages internes Ã  lâ€™Insee:\n\nPourquoi ne pas offrir le mÃªme confort Ã  lâ€™externe ?\n\n\n\n\nUne demande dâ€™utilisateurs.trices averti.e.s\n\nPar exemple Eric MauviÃ¨re"
  },
  {
    "objectID": "slides/index.html#une-source-idÃ©ale-pour-innover-dans-la-diffusion-1",
    "href": "slides/index.html#une-source-idÃ©ale-pour-innover-dans-la-diffusion-1",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Une source idÃ©ale pour innover dans la diffusion",
    "text": "Une source idÃ©ale pour innover dans la diffusion\n\nPublication en octobre 2023 des donnÃ©es et dâ€™un guide dâ€™utilisation"
  },
  {
    "objectID": "slides/index.html#une-source-idÃ©ale-pour-innover-dans-la-diffusion-2",
    "href": "slides/index.html#une-source-idÃ©ale-pour-innover-dans-la-diffusion-2",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Une source idÃ©ale pour innover dans la diffusion",
    "text": "Une source idÃ©ale pour innover dans la diffusion\n\nUn accueil enthousiaste des utilisateurs.trices"
  },
  {
    "objectID": "slides/index.html#une-source-idÃ©ale-pour-innover-dans-la-diffusion-3",
    "href": "slides/index.html#une-source-idÃ©ale-pour-innover-dans-la-diffusion-3",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Une source idÃ©ale pour innover dans la diffusion",
    "text": "Une source idÃ©ale pour innover dans la diffusion\n\nDâ€™autres institutions lâ€™utilisent maintenant pour leur diffusion\n\n\n\n\n\nStatistiques sur longue pÃ©riode des crimes et dÃ©lis"
  },
  {
    "objectID": "slides/index.html#parquet-cest-quoi",
    "href": "slides/index.html#parquet-cest-quoi",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Parquet : câ€™est quoi ?",
    "text": "Parquet : câ€™est quoi ?\n\nUn format de donnÃ©es adaptÃ©â€¦\n\nAux donnÃ©es volumineuses ;\nAux donnÃ©es complexes (exemple: 01004 pour le code commune dâ€™AmbÃ©rieu-en-Bugey)\n\n\n\n\nUn format de donnÃ©es opensource bien intÃ©grÃ©:\n\nA lâ€™Ã©cosystÃ¨me R, Python et Observable"
  },
  {
    "objectID": "slides/index.html#parquet-pourquoi",
    "href": "slides/index.html#parquet-pourquoi",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Parquet : pourquoi ?",
    "text": "Parquet : pourquoi ?\n\nFormat lÃ©ger, trÃ¨s compressÃ©:\n\nEntre 5 et 20 fois plus lÃ©ger quâ€™un CSV\nPas de perte dâ€™efficacitÃ© en lecture\n\n\n\n\n\n\n\n\n\n\nExemple: recensement de la population\n\n\n\n20 millions de lignes, 88 colonnes\n\nCSV: &gt; 5Go\nParquet: 508Mo\n\n\n\n\n\n\n\n\n\n\n\n\nExemple: statistiques de la dÃ©linquance\n\n\n\n3.5 millions de lignes:\n\nCSV: 400Mo\nParquet: 11Mo"
  },
  {
    "objectID": "slides/index.html#le-csv-en-apparence-pratique",
    "href": "slides/index.html#le-csv-en-apparence-pratique",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Le CSV: en apparence pratique",
    "text": "Le CSV: en apparence pratique\n\n\n\n\nFacile Ã  lire, facile Ã  ouvrir, mais\n\n\n\n\n\n\n\n\n\n\nProblÃ¨me: il faut scanner tout le fichier pour avoir une seule colonne\n\n\n\nLent en lecture, pas compressÃ©\nProblÃ¨me pour deviner le type dâ€™une variable\nMÃªme si on ne veut que certaines colonnes, il faut lire tout le fichier"
  },
  {
    "objectID": "slides/index.html#parquet-un-format-orientÃ©-colonne",
    "href": "slides/index.html#parquet-un-format-orientÃ©-colonne",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Parquet: un format orientÃ© colonne",
    "text": "Parquet: un format orientÃ© colonne\n\n\nPlus pratique pour nâ€™ouvrir quâ€™un sous-ensemble de variables ;\n\nPas besoin de scanner tout le fichier pour Ã©tudier quelques variables ;"
  },
  {
    "objectID": "slides/index.html#parquet-quels-avantages",
    "href": "slides/index.html#parquet-quels-avantages",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Parquet : quels avantages ?",
    "text": "Parquet : quels avantages ?\n\n\nFormat libre, open source, et indÃ©pendant du langage ;\n\n\n\nPlus de confort pour les utilisateurs:\n\nDes requÃªtes plus rapides et efficaces (seulement les donnÃ©es nÃ©cessaires sont lues)\nDes donnÃ©es conformes Ã  la mise Ã  disposition par le producteur (plus de problÃ¨me de codes communesâ€¦)"
  },
  {
    "objectID": "slides/index.html#parquet-quels-usages",
    "href": "slides/index.html#parquet-quels-usages",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Parquet : quels usages ?",
    "text": "Parquet : quels usages ?\n\nFormat privilÃ©giÃ© pour la mise Ã  disposition de donnÃ©es internes Ã  lâ€™Insee:\n\nMoins dâ€™asymÃ©tries entre utilisateurs et producteurs.\n\n\n\n\n\n\n\n\nPremiÃ¨res diffusions Ã  lâ€™externe\n\n\n\nBureaux de votes du rÃ©pertoire Ã©lectoral unique (REU):\nRecensement de la population (RP)\nPlus rÃ©cemment, la base permanente des Ã©quipements (BPE)"
  },
  {
    "objectID": "slides/index.html#parquet-quels-usages-1",
    "href": "slides/index.html#parquet-quels-usages-1",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Parquet : quels usages ?",
    "text": "Parquet : quels usages ?\n\nviewof source = Inputs.radio([\n  \"Recensement\", \"RÃ©pertoire Ã©lectoral unique\"\n], {value: \"Recensement\"})\n\n\n\n\n\n\n\n\nInputs.table(data)\n\n\n\n\n\n\n\ndata = (source == \"Recensement\") ? rp : reu\n\n\n\n\n\n\n\ndb = DuckDBClient.of({})\n\nrp = db.query(\n  \"SELECT AGED, CATL, SEXE, CANTVILLE, IPONDI FROM read_parquet('https://static.data.gouv.fr/resources/recensement-de-la-population-fichiers-detail-individus-localises-au-canton-ou-ville-2020-1/20231023-122841/fd-indcvi-2020.parquet') LIMIT 5\"\n)\nreu = db.query(\n  \"SELECT geo_adresse, id_brut_bv_reu FROM read_parquet('https://static.data.gouv.fr/resources/bureaux-de-vote-et-adresses-de-leurs-electeurs/20230626-135723/table-adresses-reu.parquet') LIMIT 5\"\n)"
  },
  {
    "objectID": "slides/index.html#pourquoi-duckdb",
    "href": "slides/index.html#pourquoi-duckdb",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Pourquoi DuckDB ?",
    "text": "Pourquoi DuckDB ?\n\nParquet ne rÃ©sout pas tout:\n\nLâ€™espace disque est optimisÃ©\nLes donnÃ©es dÃ©compressÃ©es doivent passer en RAM\n\n\nâ“ï¸ Comment analyser ces donnÃ©es sur un PC avec 8 GB de RAM ?"
  },
  {
    "objectID": "slides/index.html#pourquoi-duckdb-1",
    "href": "slides/index.html#pourquoi-duckdb-1",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Pourquoi DuckDB ?",
    "text": "Pourquoi DuckDB ?"
  },
  {
    "objectID": "slides/index.html#pourquoi-duckdb-2",
    "href": "slides/index.html#pourquoi-duckdb-2",
    "title": "Le format de donnÃ©es Parquet",
    "section": "Pourquoi DuckDB ?",
    "text": "Pourquoi DuckDB ?\n\n\n\nDuckDB est un utilitaire open source\n\nUn logiciel en ligne de commande tout simple (20Mo)â€¦\nDes librairies ,  et Observable pour simplifier lâ€™usage\nRequÃªtes SQL mais aussi intÃ©gration tidyverse pour \n\n\n\n\n\n\n\n\n\nDuckDB est trÃ¨s efficace:\n\nMoteur SQL enrichi avec des fonctions trÃ¨s pratiques pour lâ€™analyse\nOptimisations automatiques\nVisualisations sans exÃ©cuter sur toute la base\n\n\n\n\nğŸ’¡ Les avantages du monde des bases de donnÃ©es sans ses inconvÃ©nients"
  },
  {
    "objectID": "slides/index.html#reproductibilitÃ©-des-exemples",
    "href": "slides/index.html#reproductibilitÃ©-des-exemples",
    "title": "Le format de donnÃ©es Parquet",
    "section": "ReproductibilitÃ© des exemples",
    "text": "ReproductibilitÃ© des exemples\n\n\n\nPlateforme de data science dÃ©veloppÃ©e par lâ€™Insee\n\nEnvironnements standardisÃ©s , \nAccessible aux chercheurs.euses pour lâ€™enseignement ğŸ˜‰\n\n\n\n\nEnvironnements prÃ©configurÃ©s lanÃ§ables en 1 clic:\n\n\n\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\nSi vous avez un compte, nâ€™hÃ©sitez pas Ã  essayer les exemples prÃ©sentÃ©s en live !"
  },
  {
    "objectID": "slides/index.html#idÃ©es",
    "href": "slides/index.html#idÃ©es",
    "title": "Le format de donnÃ©es Parquet",
    "section": "IdÃ©es",
    "text": "IdÃ©es\n\nTuto ssphub\nFaire une carte des rÃ©sidences secondaires en France\nModes de transport\nDistribution par Ã¢ge\n\n\n\n\nAtelier tuto@mate (retour Ã  la page principale de ce site)"
  },
  {
    "objectID": "tuto/observablehq.html",
    "href": "tuto/observablehq.html",
    "title": "Utilisation du format Parquet avec Observable illustrÃ© Ã  partir de quelques exemples",
    "section": "",
    "text": "Page observablehq"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Atelier tuto@mate sur le format Parquet",
    "section": "",
    "text": "Un ensemble de ressources pour prÃ©senter les enjeux de lâ€™utilisation du format Parquet illustrÃ© Ã  partir des donnÃ©es du recensement.\n\n\n\n\n\n\n\n\n\n\nLe format de donnÃ©es Parquet\n\n\nSlides prÃ©sentant les enjeux de lâ€™utilisation du format Parquet et lâ€™Ã©cosystÃ¨me associÃ©\n\n\n\nLino Galiana\n\n\nNov 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUtilisation du format Parquet avec  illustrÃ© Ã  partir de quelques exemples\n\n\nTutoriel R\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUtilisation du format Parquet avec Python illustrÃ© Ã  partir de quelques exemples\n\n\nTutoriel Python\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUtilisation du format Parquet avec Observable illustrÃ© Ã  partir de quelques exemples\n\n\nTutoriel Observable\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\nNo matching items\n\n\nReplay de la prÃ©sentation:"
  },
  {
    "objectID": "tuto/python.html",
    "href": "tuto/python.html",
    "title": "Utilisation du format Parquet avec Python illustrÃ© Ã  partir de quelques exemples",
    "section": "",
    "text": "Ce tutoriel nâ€™est pas encore fini, il sera progressivement enrichi\nCe tutoriel vise Ã  offrir une approche complÃ©mentaire au guide dâ€™utilisation des donnÃ©es du recensement au format Parquet publiÃ© sur https://ssphub.netlify.app pour accompagner la diffusion de celles-ci par lâ€™Insee.\nIl sâ€™agit dâ€™un tutoriel prÃ©parÃ© pour lâ€™atelier tuto@mate Ã  lâ€™EHESS le 5 novembre 2024. Ce tutoriel est exclusivement en R. Les slides de la prÃ©sentation sont disponibles ci-dessous:\nDÃ©rouler les slides ci-dessous ou cliquer ici pour afficher les slides en plein Ã©cran.\nIl propose des exemples variÃ©s pour illustrer la simplicitÃ© dâ€™usage du format Parquet. Parmi ceux-ci, Ã  partir du recensement de la population:"
  },
  {
    "objectID": "tuto/python.html#requÃªtes-sur-les-colonnes-select",
    "href": "tuto/python.html#requÃªtes-sur-les-colonnes-select",
    "title": "Utilisation du format Parquet avec Python illustrÃ© Ã  partir de quelques exemples",
    "section": "RequÃªtes sur les colonnes (SELECT)",
    "text": "RequÃªtes sur les colonnes (SELECT)\nLâ€™une des forces du format Parquet est de simplifier lâ€™import de fichiers volumineux qui ne comportent que quelques colonnes nous intÃ©ressant. Par exemple, la table des individus comporte 88 colonnes, il est peu probable quâ€™une seule analyse sâ€™intÃ©resse Ã  toutes celles-ci (ou elle risque dâ€™Ãªtre fort indigeste).\n\nComme cela est illustrÃ© dans ?@tip-optimisation-duckdb, la diffÃ©rence de volumÃ©trie entre un fichier non filtrÃ© et un fichier filtrÃ© est importante.\n\nquery = (\n  f\"FROM read_parquet(\\\"{filename_table_individu}\\\") \"\n  \"SELECT IPONDI AS poids, AGED, VOIT \"\n  \"LIMIT 10\"\n)\nduckdb.sql(query).to_df()\n\n\n\n\n\n\n\n\npoids\nAGED\nVOIT\n\n\n\n\n0\n0.865066\n74\n0\n\n\n1\n4.987931\n39\n1\n\n\n2\n4.987931\n9\n1\n\n\n3\n5.013547\n55\n2\n\n\n4\n3.478368\n1\n0\n\n\n5\n3.478368\n43\n0\n\n\n6\n3.478368\n38\n0\n\n\n7\n1.003585\n46\n1\n\n\n8\n1.003585\n16\n1\n\n\n9\n0.984087\n59\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\nComprendre lâ€™optimisation permise par Parquet et DuckDB\n\n\n\n\n\nPour rÃ©duire la volumÃ©trie des donnÃ©es importÃ©es, il est possible de mettre en oeuvre deux stratÃ©gies:\n\nNâ€™importer quâ€™un nombre limitÃ© de colonnes\nNâ€™importer quâ€™un nombre limitÃ© de lignes\n\nComme cela a Ã©tÃ© Ã©voquÃ© dans les slides, le format Parquet est particuliÃ¨rement optimisÃ© pour le premier besoin. Câ€™est donc gÃ©nÃ©ralement la premiÃ¨re optimisation mise en oeuvre. Pour sâ€™en convaincre on peut regarder la taille des donnÃ©es importÃ©es dans deux cas:\n\nOn utilise beaucoup de lignes mais peu de colonnes\nOn utilise beaucoup de colonnes mais peu de lignes\n\nPour cela, nous utilisons la fonction SQL EXPLAIN ANALYZE disponible dans duckdb. Elle dÃ©compose le plan dâ€™exÃ©cution de duckdb, ce qui nous permettra de comprendre la stratÃ©gie dâ€™optimisation. Elle permet aussi de connaÃ®tre le volume de donnÃ©es importÃ©es lorsquâ€™on rÃ©cupÃ¨re un fichier dâ€™internet. En effet, duckdb est malin: plutÃ´t que de tÃ©lÃ©charger un fichier entier pour nâ€™en lire quâ€™une partie, la librairie est capable de nâ€™importer que les blocs du fichier qui lâ€™intÃ©resse.\nCeci nÃ©cessite lâ€™utilisation de lâ€™extension httpfs (un peu lâ€™Ã©quivalent des library de R en duckdb). Elle sâ€™installe et sâ€™utilise de la maniÃ¨re suivante\n\nduckdb.sql(\"INSTALL httpfs; LOAD httpfs;\")\n\nDemandons Ã  DuckDB dâ€™exÃ©cuter la requÃªte â€œbeaucoup de colonnes, pas beaucoup de lignesâ€ et regardons le plan dâ€™exÃ©cution et les informations donnÃ©es par DuckDB:\n\n\nVoir le plan : â€œbeaucoup de colonnes, pas beaucoup de lignesâ€\n\n\nurl_bpe = files_to_download.get(\"table_bpe\").get(\"url\")\n\nplan = duckdb.query(\nf\"\"\"\nEXPLAIN ANALYZE\nFROM read_parquet(\"{url_bpe}\")\nSELECT *\nLIMIT 5\n\"\"\"\n) \n\n\nprint(\n  plan.to_df()['explain_value'].iloc[0]\n)\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚    Query Profiling Information    â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n EXPLAIN ANALYZE FROM read_parquet(\"https://minio.lab.sspcloud.fr/lgaliana/diffusion/BPE23.parquet\") SELECT * LIMIT 5 \nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚         HTTPFS HTTP Stats         â”‚â”‚\nâ”‚â”‚                                   â”‚â”‚\nâ”‚â”‚            in: 60.2 MiB           â”‚â”‚\nâ”‚â”‚            out: 0 bytes           â”‚â”‚\nâ”‚â”‚              #HEAD: 1             â”‚â”‚\nâ”‚â”‚              #GET: 3              â”‚â”‚\nâ”‚â”‚              #PUT: 0              â”‚â”‚\nâ”‚â”‚              #POST: 0             â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚               Total Time: 5.71s              â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚           QUERY           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      EXPLAIN_ANALYZE      â”‚\nâ”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚\nâ”‚           0 Rows          â”‚\nâ”‚          (0.00s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      STREAMING_LIMIT      â”‚\nâ”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚\nâ”‚           5 Rows          â”‚\nâ”‚          (0.00s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚         TABLE_SCAN        â”‚\nâ”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚\nâ”‚         Function:         â”‚\nâ”‚        READ_PARQUET       â”‚\nâ”‚                           â”‚\nâ”‚        Projections:       â”‚\nâ”‚             AN            â”‚\nâ”‚           NOMRS           â”‚\nâ”‚           CNOMRS          â”‚\nâ”‚          NUMVOIE          â”‚\nâ”‚           INDREP          â”‚\nâ”‚          TYPVOIE          â”‚\nâ”‚          LIBVOIE          â”‚\nâ”‚            CADR           â”‚\nâ”‚           CODPOS          â”‚\nâ”‚           DEPCOM          â”‚\nâ”‚            DEP            â”‚\nâ”‚            REG            â”‚\nâ”‚            DOM            â”‚\nâ”‚            SDOM           â”‚\nâ”‚           TYPEQU          â”‚\nâ”‚           SIRET           â”‚\nâ”‚      STATUT_DIFFUSION     â”‚\nâ”‚          CANTINE          â”‚\nâ”‚          INTERNAT         â”‚\nâ”‚            RPI            â”‚\nâ”‚             EP            â”‚\nâ”‚           CL_PGE          â”‚\nâ”‚            SECT           â”‚\nâ”‚    ACCES_AIRE_PRATIQUE    â”‚\nâ”‚        ACCES_LIBRE        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\n\nVoir le plan : â€œpas de colonnes, beaucoup de lignesâ€\n\n\nplan = duckdb.sql(\n  f\"\"\"\n  EXPLAIN ANALYZE\n  SELECT TYPEQU, LONGITUDE, LATITUDE FROM read_parquet(\"{url_bpe}\") LIMIT 10000\n  \"\"\"\n)\n\n\nprint(\n  plan.to_df()['explain_value'].iloc[0]\n)\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚    Query Profiling Information    â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n   EXPLAIN ANALYZE   SELECT TYPEQU, LONGITUDE, LATITUDE FROM read_parquet(\"https://minio.lab.sspcloud.fr/lgaliana/diffusion/BPE23.parquet\") LIMIT 10000   \nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚         HTTPFS HTTP Stats         â”‚â”‚\nâ”‚â”‚                                   â”‚â”‚\nâ”‚â”‚            in: 13.8 MiB           â”‚â”‚\nâ”‚â”‚            out: 0 bytes           â”‚â”‚\nâ”‚â”‚              #HEAD: 1             â”‚â”‚\nâ”‚â”‚              #GET: 4              â”‚â”‚\nâ”‚â”‚              #PUT: 0              â”‚â”‚\nâ”‚â”‚              #POST: 0             â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚â”‚               Total Time: 1.95s              â”‚â”‚\nâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚           QUERY           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      EXPLAIN_ANALYZE      â”‚\nâ”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚\nâ”‚           0 Rows          â”‚\nâ”‚          (0.00s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      STREAMING_LIMIT      â”‚\nâ”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚\nâ”‚         10000 Rows        â”‚\nâ”‚          (0.00s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚         TABLE_SCAN        â”‚\nâ”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚\nâ”‚         Function:         â”‚\nâ”‚        READ_PARQUET       â”‚\nâ”‚                           â”‚\nâ”‚        Projections:       â”‚\nâ”‚           TYPEQU          â”‚\nâ”‚         LONGITUDE         â”‚\nâ”‚          LATITUDE         â”‚\nâ”‚                           â”‚\nâ”‚         12288 Rows        â”‚\nâ”‚          (1.95s)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\nLa comparaison de ces plans dâ€™exÃ©cution montre lâ€™intÃ©rÃªt de faire un filtre sur les colonnes : les besoins computationnels sont drastiquement diminuÃ©s. Le filtre sur les lignes nâ€™arrive que dans un second temps, une fois les colonnes sÃ©lectionnÃ©es.\nPourquoi seulement un rapport de 1 Ã  4 entre le poids des deux fichiers ? Câ€™est parce que nos requÃªtes comportent toute deux la variable IPONDI (les poids Ã  utiliser pour extrapoler lâ€™Ã©chantillon Ã  la population) qui est Ã  haute prÃ©cision lÃ  oÃ¹ beaucoup dâ€™autres colonnes comportent un nombre rÃ©duit de modalitÃ©s et sont donc peu volumineuses.\n\n\n\nDuckDB propose Ã©galement des fonctionnalitÃ©s pour extraire des colonnes Ã  travers des expressions rÃ©guliÃ¨res. Cette approche est Ã©galement possible avec le tidyverse\n\nduckdb.sql(\n  f\"\"\"\n    FROM read_parquet(\\\"{filename_table_individu}\\\")\n    SELECT IPONDI AS poids, COLUMNS('.*AGE.*')\n    LIMIT 10\n  \"\"\"\n).to_df()\n\n\n\n\n\n\n\n\npoids\nAGED\nAGER20\nAGEREV\nAGEREVQ\n\n\n\n\n0\n0.865066\n74\n79\n73\n70\n\n\n1\n4.987931\n39\n39\n38\n35\n\n\n2\n4.987931\n9\n10\n8\n5\n\n\n3\n5.013547\n55\n54\n54\n50\n\n\n4\n3.478368\n1\n2\n0\n0\n\n\n5\n3.478368\n43\n54\n42\n40\n\n\n6\n3.478368\n38\n39\n37\n35\n\n\n7\n1.003585\n46\n54\n45\n45\n\n\n8\n1.003585\n16\n17\n15\n15\n\n\n9\n0.984087\n59\n64\n58\n55"
  },
  {
    "objectID": "tuto/python.html#requÃªtes-sur-les-lignes-where",
    "href": "tuto/python.html#requÃªtes-sur-les-lignes-where",
    "title": "Utilisation du format Parquet avec Python illustrÃ© Ã  partir de quelques exemples",
    "section": "RequÃªtes sur les lignes (WHERE)",
    "text": "RequÃªtes sur les lignes (WHERE)\n\nduckdb.sql(\n    f\"\"\"\n    FROM read_parquet(\"{filename_table_individu}\")\n    SELECT IPONDI, AGED, DEPT\n    WHERE DEPT IN ('11', '31', '34')\n    LIMIT 10\n    \"\"\"\n).to_df()\n\n\n\n\n\n\n\n\nIPONDI\nAGED\nDEPT\n\n\n\n\n0\n5.027778\n59\n11\n\n\n1\n5.027778\n83\n11\n\n\n2\n4.996593\n50\n11\n\n\n3\n4.996593\n26\n11\n\n\n4\n5.148676\n9\n11\n\n\n5\n5.148676\n38\n11\n\n\n6\n5.148676\n49\n11\n\n\n7\n5.000000\n88\n11\n\n\n8\n5.000000\n88\n11\n\n\n9\n5.297153\n18\n11\n\n\n\n\n\n\n\nLes filtres sur les observations peuvent Ãªtre faits Ã  partir de critÃ¨res sur plusieurs colonnes. Par exemple, pour ne conserver que les observations de la ville de Nice oÃ¹ la date dâ€™emmÃ©nagement est postÃ©rieure Ã  2020, la requÃªte suivante peut Ãªtre utilisÃ©e :\n\nduckdb.sql(\n    f\"\"\"\n    FROM read_parquet(\"{filename_table_logement}\")\n    SELECT *\n    WHERE COMMUNE = '06088' AND AEMM &gt; 2020\n    LIMIT 10\n    \"\"\"\n).to_df()\n\n\n\n\n\n\n\n\nCOMMUNE\nARM\nIRIS\nACHL\nAEMM\nAEMMR\nAGEMEN8\nANEM\nANEMR\nASCEN\n...\nSTOCD\nSURF\nTACTM\nTPM\nTRANSM\nTRIRIS\nTYPC\nTYPL\nVOIT\nWC\n\n\n\n\n0\n06088\nZZZZZ\n060880101\nA11\n2022\n9\n40\n0\n0\n2\n...\n21\n4\n11\n1\n5\n060421\n3\n2\n1\nZ\n\n\n1\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n40\n1\n0\n2\n...\n10\n2\n11\n1\n6\n060421\n3\n2\n0\nZ\n\n\n2\n06088\nZZZZZ\n060880101\nA12\n2021\n9\n25\n1\n0\n2\n...\n21\n2\n12\nZ\nZ\n060421\n3\n2\n0\nZ\n\n\n3\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n40\n1\n0\n2\n...\n21\n3\n11\n1\n5\n060421\n3\n2\n1\nZ\n\n\n4\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n40\n1\n0\n2\n...\n21\n3\n11\n1\n5\n060421\n3\n2\n1\nZ\n\n\n5\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n40\n1\n0\n2\n...\n21\n2\n11\n1\n2\n060421\n3\n2\n0\nZ\n\n\n6\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n25\n1\n0\n2\n...\n21\n2\n11\n1\n2\n060421\n2\n2\n0\nZ\n\n\n7\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n40\n1\n0\n2\n...\n21\n2\n11\n1\n2\n060421\n3\n2\n0\nZ\n\n\n8\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n25\n1\n0\n2\n...\n21\n5\n11\n1\n6\n060421\n3\n2\n1\nZ\n\n\n9\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n55\n1\n0\n2\n...\n21\n3\n12\nZ\nZ\n060421\n2\n2\n0\nZ\n\n\n\n\n10 rows Ã— 69 columns"
  },
  {
    "objectID": "tuto/python.html#exemples-sans-groupes",
    "href": "tuto/python.html#exemples-sans-groupes",
    "title": "Utilisation du format Parquet avec Python illustrÃ© Ã  partir de quelques exemples",
    "section": "Exemples sans groupes",
    "text": "Exemples sans groupes\nLa fonction DISTINCT appliquÃ©e Ã  la variable ARM permet dâ€™extraire la liste des codes arrondissements prÃ©sents dans la base de donnÃ©es.\n\nquery = f\"\"\"\nFROM read_parquet('{filename_table_logement}')\nSELECT DISTINCT ARM\nWHERE NOT ARM LIKE '%ZZZZZ%'\nORDER BY ARM\n\"\"\"\n\nresult = \", \".join(duckdb.sql(query).to_df()[\"ARM\"])\n\nIl est possible dâ€™extraire des statistiques beaucoup plus raffinÃ©es par le biais dâ€™une requÃªte SQL plus complexe. Par exemple pour calculer le nombre dâ€™habitants de Toulouse qui ont changÃ© de logement en un an:\n\nquery = f\"\"\"\nFROM read_parquet(\"{filename_table_logement}\")\nSELECT CAST(SUM(IPONDL * CAST(INPER AS INT)) AS INT) \nAS habitants_toulouse_demenagement\nWHERE COMMUNE = '31555' \nAND IRANM NOT IN ('1', 'Z') \nAND INPER != 'Y'\n\"\"\"\n\nduckdb.sql(query).to_df()\n\n\n\n\n\n\n\n\nhabitants_toulouse_demenagement\n\n\n\n\n0\n86364"
  },
  {
    "objectID": "tuto/python.html#statistiques-par-groupe",
    "href": "tuto/python.html#statistiques-par-groupe",
    "title": "Utilisation du format Parquet avec Python illustrÃ© Ã  partir de quelques exemples",
    "section": "Statistiques par groupe",
    "text": "Statistiques par groupe\nSQL et dplyr permettent dâ€™aller loin dans la finesse des statistiques descriptives mises en oeuvre. Cela sera illustrÃ© Ã  lâ€™aide de plusieurs exemples rÃ©flÃ©tant des statistiques pouvant Ãªtre construites grÃ¢ce Ã  ces donnÃ©es dÃ©taillÃ©es.\n\nExemple 1: pyramide des Ã¢ges dans lâ€™Aude, lâ€™HÃ©rault et le Gard\nLe premier exemple est un comptage sur trois dÃ©partements. Il illustre la dÃ©marche suivante:\n\nOn se restreint aux observations dâ€™intÃ©rÃªt (ici 3 dÃ©partements)\nOn applique la fonction summarise pour calculer une statistique par groupe, en lâ€™occurrence la somme des pondÃ©rations\nOn retravaille les donnÃ©es\n\nEnsuite, une fois que nos donnÃ©es sont rÃ©cupÃ©rÃ©es dans R, on peut faire la figure avec ggplot\n\n\n\n\nListingÂ 1: Pyramide des Ã¢ges dans lâ€™Aude, lâ€™HÃ©rault et le Gard\n\n\npyramide_ages = duckdb.sql(\n        f\"\"\"\n        FROM read_parquet(\"{filename_table_individu}\")\n        SELECT AGED, DEPT AS departement, SUM(IPONDI) AS individus\n        WHERE DEPT IN ('11', '31', '34')\n        GROUP BY AGED, DEPT\n        ORDER BY DEPT, AGED\n        \"\"\"\n    ).to_df()\n\n# Create the plot\nplot = (\n    ggplot(pyramide_ages, aes(x='AGED', y='individus'))\n    + geom_bar(aes(fill='departement'), stat=\"identity\")\n    + geom_vline(xintercept=18, color=\"grey\", linetype=\"dashed\")\n    + facet_wrap('~departement', scales=\"free_y\", nrow=3)\n    + theme_minimal()\n    + labs(y=\"Individus recensÃ©s\", x=\"Ã‚ge\")\n)\n\nplot\n\n\n\n\n\n\n\n\n\n\n\n\n\nExemple 2: rÃ©partition des plus de 60 ans par dÃ©partement\nLâ€™objectif de ce deuxiÃ¨me exemple est dâ€™illustrer la construction dâ€™une statistique un peu plus complexe et la maniÃ¨re de projeter celle-ci sur une carte.\nPour avoir la rÃ©partition des plus de 60 ans par dÃ©partement, quelques lignes de dplyr suffisent:\n\nimport pandas as pd\nimport duckdb\n\n# Query to calculate total population and population over 60\npart_population_60_plus = duckdb.sql(\n    f\"\"\"\n    FROM read_parquet(\"{filename_table_individu}\")\n    SELECT \n        DEPT,\n        SUM(IPONDI) AS total_population,\n        SUM(CASE WHEN AGED &gt; 60 THEN IPONDI ELSE 0 END) AS population_60_plus\n    GROUP BY DEPT\n    \"\"\"\n).to_df()\n\n# Calculate percentage of population over 60\npart_population_60_plus['pourcentage_60_plus'] = (\n    part_population_60_plus['population_60_plus'] / part_population_60_plus['total_population'] * 100\n)\n\n# Display the result\npart_population_60_plus\n\n\n\n\n\n\n\n\nDEPT\ntotal_population\npopulation_60_plus\npourcentage_60_plus\n\n\n\n\n0\n36\n2.184686e+05\n77537.249050\n35.491251\n\n\n1\n37\n6.119776e+05\n171305.033516\n27.992044\n\n\n2\n62\n1.463108e+06\n372022.387602\n25.426859\n\n\n3\n85\n6.925099e+05\n219234.728530\n31.657991\n\n\n4\n87\n3.721453e+05\n117712.548104\n31.630808\n\n\n...\n...\n...\n...\n...\n\n\n95\n57\n1.049516e+06\n278799.626512\n26.564589\n\n\n96\n46\n1.743972e+05\n67122.352897\n38.488203\n\n\n97\n47\n3.309191e+05\n111975.473233\n33.837718\n\n\n98\n68\n7.671218e+05\n201979.717545\n26.329550\n\n\n99\n76\n1.254974e+06\n331670.694285\n26.428497\n\n\n\n\n100 rows Ã— 4 columns\n\n\n\nIl ne reste plus quâ€™Ã  projeter ceci sur une carte. Pour cela, un join Ã  notre fond de carte suffit. Comme les donnÃ©es sont agrÃ©gÃ©es et dÃ©jÃ  dans R, il nâ€™y a rien de spÃ©cifique Ã  duckdb ici.\n\n\nAssociation de part_population_60_plus au fond de carte des dÃ©partements\n# Joindre les donnÃ©es au fond de carte des dÃ©partements\n\ndepartements_60_plus_gpd = (\n  departements\n    .merge(\n      part_population_60_plus,\n      left_on = \"INSEE_DEP\",\n      right_on = \"DEPT\"\n    )\n)\n\n\nFinalement, il ne reste plus quâ€™Ã  produire la carte:\n\ndepartements_60_plus_gpd['pourcentage_60_plus_d'] = pd.qcut(\n  departements_60_plus_gpd['pourcentage_60_plus'],\n  q=4\n)\n\n\n(\n  ggplot(departements_60_plus_gpd) +\n    geom_map(aes(fill = \"pourcentage_60_plus_d\")) + \n    scale_fill_brewer(palette = \"PuBuGn\", direction = 1) + \n    theme_void() + \n    labs(\n        title = \"Part des personnes de plus de 60 ans par dÃ©partement\",\n        caption = \"Source: Insee, Fichiers dÃ©tails du recensement de la population\",\n        fill = \"Part (%)\"\n    )\n)\n\n\n\n\n\n\n\n\nSi on prÃ©fÃ¨re reprÃ©senter ceci sous forme de tableau, on peut utiliser le package great tables. Cela nÃ©cessite quelques manipulations de donnÃ©es en amont.\n\npart_population_60_plus_dep = part_population_60_plus.merge(\n  departements.loc[:, [\"INSEE_DEP\", \"LIBELLE_DEPARTEMENT\"]],\n  left_on = \"DEPT\",\n  right_on = \"INSEE_DEP\"\n)\npart_population_60_plus_dep[\"departement\"] = part_population_60_plus_dep[\"LIBELLE_DEPARTEMENT\"] + \" (\" + part_population_60_plus_dep[\"DEPT\"]  + \")\"\n\npart_population_60_plus_dep = part_population_60_plus_dep.sort_values(\"pourcentage_60_plus\", ascending=False).head(10)\n\n\nfrom great_tables import *\n(\n  GT(\n    part_population_60_plus_dep.loc[\n      :, ['departement', 'total_population', 'population_60_plus', 'pourcentage_60_plus']\n    ]\n  )\n  .fmt_number(columns=[\n    \"total_population\", \"population_60_plus\"\n  ], compact=True)\n  .fmt_percent(\"pourcentage_60_plus\", scale_values = False)\n  .fmt_nanoplot(columns=\"pourcentage_60_plus\", plot_type=\"bar\")\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\ndepartement\ntotal_population\npopulation_60_plus\npourcentage_60_plus\n\n\n\n\nCreuse (23)\n116.18K\n45.56K\n\n\n\n\n39.2\n\n\n\n\nLot (46)\n174.40K\n67.12K\n\n\n\n\n38.5\n\n\n\n\nNiÃ¨vre (58)\n202.73K\n76.11K\n\n\n\n\n37.5\n\n\n\n\nDordogne (24)\n413.18K\n153.40K\n\n\n\n\n37.1\n\n\n\n\nCantal (15)\n144.32K\n51.59K\n\n\n\n\n35.7\n\n\n\n\nGers (32)\n191.74K\n68.26K\n\n\n\n\n35.6\n\n\n\n\nIndre (36)\n218.47K\n77.54K\n\n\n\n\n35.5\n\n\n\n\nCharente-Maritime (17)\n655.65K\n232.01K\n\n\n\n\n35.4\n\n\n\n\nAllier (03)\n335.38K\n118.48K\n\n\n\n\n35.3\n\n\n\n\nCorrÃ¨ze (19)\n239.29K\n84.51K\n\n\n\n\n35.3\n\n\n\n\n\n\n\n\n        \n\n\n\n\nExemple 3: part des rÃ©sidences secondaires et des logements vacants\nIl est tout Ã  fait possible de faire des Ã©tapes antÃ©rieures de prÃ©paration de donnÃ©es, notamment de crÃ©ation de variables avec mutate.\nLâ€™exemple suivant illustre la prÃ©paration de donnÃ©es avant la construction de statistiques descriptives de la maniÃ¨re suivante:\n\nCrÃ©ation dâ€™une variable de dÃ©partement Ã  partir du code commune\nDÃ©compte des logements par dÃ©partement\n\nSuite du tutoriel Ã  venir\n\nimport shutil\nshutil.rmtree(\"data\")"
  },
  {
    "objectID": "tuto/python.html#footnotes",
    "href": "tuto/python.html#footnotes",
    "title": "Utilisation du format Parquet avec Python illustrÃ© Ã  partir de quelques exemples",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPour en savoir plus sur ce projet, se rendre sur la documentation du projet.â†©ï¸"
  }
]
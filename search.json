[
  {
    "objectID": "tuto/r.html",
    "href": "tuto/r.html",
    "title": "Utilisation du format Parquet avec  illustré à partir de quelques exemples",
    "section": "",
    "text": "Ce tutoriel vise à offrir une approche complémentaire au guide d’utilisation des données du recensement au format Parquet publié sur https://ssphub.netlify.app pour accompagner la diffusion de celles-ci par l’Insee.\nIl s’agit d’un tutoriel préparé pour l’atelier tuto@mate à l’EHESS le 5 novembre 2024. Ce tutoriel est exclusivement en R. Les slides de la présentation sont disponibles ci-dessous:\nIl propose des exemples variés pour illustrer la simplicité d’usage du format Parquet. Parmi ceux-ci, à partir du recensement de la population:\nA partir de la base permanent des équipements (BPE):"
  },
  {
    "objectID": "tuto/r.html#footnotes",
    "href": "tuto/r.html#footnotes",
    "title": "Utilisation du format Parquet avec  illustré à partir de quelques exemples",
    "section": "Footnotes",
    "text": "Footnotes\n\nSi vous avez clôné le dépôt disponible sur Github , un environnement virtuel renv vous permet de recréer la même configuration logicielle que celle utilisée pour générer cette page. Pour cela, il suffit de faire renv::restore().↩︎\nPour en savoir plus sur ce projet, se rendre sur la documentation du projet.↩︎"
  },
  {
    "objectID": "slides/index.html#plan",
    "href": "slides/index.html#plan",
    "title": "Le format de données Parquet",
    "section": "Plan",
    "text": "Plan\n\nContexte\nPourquoi le format Parquet ?\nL’écosystème Parquet\nDémonstration"
  },
  {
    "objectID": "slides/index.html#le-recensement-de-la-population",
    "href": "slides/index.html#le-recensement-de-la-population",
    "title": "Le format de données Parquet",
    "section": "Le recensement de la population",
    "text": "Le recensement de la population\n\nMission historique de l’Insee depuis 1946\n\nL’Insee organise, les communes réalisent la collecte\n\n\n\n\nUne source d’utilité publique :\n\nPopulations légales: dotations de l’État aux communes, organisation des scrutins, équipements publics, etc.\nRecherche: caractéristiques socio-démographiques, mobilités…\n\n\n\n\n\n\n\n\nEnquêtes annuelles de recensement (EAR) depuis 2004\n\n\n\nPour une commune de moins de 10 000 habitants:\n\nCollecte exhaustive une fois tous les 5 ans.\n\nPour une commune de plus de 10 000 habitants:\n\nChaque année, 8% des logements sont recensés ;\nLe résultat du recensement est calculé à partir des 5 dernières années (=40% logements)\n\n\nDocumentation technique sur le recensement"
  },
  {
    "objectID": "slides/index.html#une-diffusion-sous-plusieurs-formes",
    "href": "slides/index.html#une-diffusion-sous-plusieurs-formes",
    "title": "Le format de données Parquet",
    "section": "Une diffusion sous plusieurs formes",
    "text": "Une diffusion sous plusieurs formes\n\nDiffusion sur insee.fr sous plusieurs formes:\n\nPages “dynamiques” sur insee.fr\nExports d’agrégats depuis statistiques-locales.insee.fr/\nDes données, des cartes, des publications, etc..\n\n\n\n\nMais beaucoup de gestes manuels pour obtenir un seul agrégat\n\n\n\n\nUne information parfois difficile à trouver sur le site de l’Insee"
  },
  {
    "objectID": "slides/index.html#une-diffusion-sous-plusieurs-formes-1",
    "href": "slides/index.html#une-diffusion-sous-plusieurs-formes-1",
    "title": "Le format de données Parquet",
    "section": "Une diffusion sous plusieurs formes",
    "text": "Une diffusion sous plusieurs formes\n\nLes fichiers agrégés\n\n\n\nStructure type: une ligne par commune ou IRIS\n\n\n\nTaille de chaque fichier relativement raisonnable\n\nCSV généralement de quelques Mo, jusqu’à 150 Mo"
  },
  {
    "objectID": "slides/index.html#une-diffusion-sous-plusieurs-formes-2",
    "href": "slides/index.html#une-diffusion-sous-plusieurs-formes-2",
    "title": "Le format de données Parquet",
    "section": "Une diffusion sous plusieurs formes",
    "text": "Une diffusion sous plusieurs formes\n\nLes micro-données anonymisées\n\n\nStructure type: une ligne par observation\n\nUn logement, un individu…\n\n\n\n\nPermet de construire d’autres croisements que ceux proposés sur insee.fr\n\n\n\n\n\n\n\n\n\nUn format destiné à des utilisateurs avancés\n\n\n\nUne source riche mais des précautions d’emploi à respecter:\n\nPondérations à prendre en compte\nInterprétation des petits effectifs…\n\nDemande une certaine expertise"
  },
  {
    "objectID": "slides/index.html#défi",
    "href": "slides/index.html#défi",
    "title": "Le format de données Parquet",
    "section": "Défi",
    "text": "Défi\n\nCe sont des fichiers très volumineux\n\nJusqu’à 100 variables et 25 millions de lignes\nFichier CSV jusqu’à 5 Go\n\n\n\n\nPour l’Insee : complexes à produire et valider avant diffusion\n\n\n\n\nPour l’utilisateur.trice : complexes à télécharger, stocker et exploiter"
  },
  {
    "objectID": "slides/index.html#solution-historique",
    "href": "slides/index.html#solution-historique",
    "title": "Le format de données Parquet",
    "section": "Solution historique",
    "text": "Solution historique\n\nDiffusion zippée (CSV) ou format DBase (format propriétaire)\n\nDécoupage en fichiers par grandes zones de régions"
  },
  {
    "objectID": "slides/index.html#une-source-idéale-pour-innover-dans-la-diffusion",
    "href": "slides/index.html#une-source-idéale-pour-innover-dans-la-diffusion",
    "title": "Le format de données Parquet",
    "section": "Une source idéale pour innover dans la diffusion",
    "text": "Une source idéale pour innover dans la diffusion\n\nMontée en puissance du format Parquet pour les usages internes à l’Insee:\n\nPourquoi ne pas offrir le même confort à l’externe ?\n\n\n\n\nUne demande d’utilisateurs.trices averti.e.s\n\nPar exemple Eric Mauvière"
  },
  {
    "objectID": "slides/index.html#une-source-idéale-pour-innover-dans-la-diffusion-1",
    "href": "slides/index.html#une-source-idéale-pour-innover-dans-la-diffusion-1",
    "title": "Le format de données Parquet",
    "section": "Une source idéale pour innover dans la diffusion",
    "text": "Une source idéale pour innover dans la diffusion\n\nPublication en octobre 2023 des données et d’un guide d’utilisation"
  },
  {
    "objectID": "slides/index.html#une-source-idéale-pour-innover-dans-la-diffusion-2",
    "href": "slides/index.html#une-source-idéale-pour-innover-dans-la-diffusion-2",
    "title": "Le format de données Parquet",
    "section": "Une source idéale pour innover dans la diffusion",
    "text": "Une source idéale pour innover dans la diffusion\n\nUn accueil enthousiaste des utilisateurs.trices"
  },
  {
    "objectID": "slides/index.html#une-source-idéale-pour-innover-dans-la-diffusion-3",
    "href": "slides/index.html#une-source-idéale-pour-innover-dans-la-diffusion-3",
    "title": "Le format de données Parquet",
    "section": "Une source idéale pour innover dans la diffusion",
    "text": "Une source idéale pour innover dans la diffusion\n\nD’autres institutions l’utilisent maintenant pour leur diffusion\n\n\n\n\n\nStatistiques sur longue période des crimes et délis"
  },
  {
    "objectID": "slides/index.html#parquet-cest-quoi",
    "href": "slides/index.html#parquet-cest-quoi",
    "title": "Le format de données Parquet",
    "section": "Parquet : c’est quoi ?",
    "text": "Parquet : c’est quoi ?\n\nUn format de données adapté…\n\nAux données volumineuses ;\nAux données complexes (exemple: 01004 pour le code commune d’Ambérieu-en-Bugey)\n\n\n\n\nUn format de données opensource bien intégré:\n\nA l’écosystème R, Python et Observable"
  },
  {
    "objectID": "slides/index.html#parquet-pourquoi",
    "href": "slides/index.html#parquet-pourquoi",
    "title": "Le format de données Parquet",
    "section": "Parquet : pourquoi ?",
    "text": "Parquet : pourquoi ?\n\nFormat léger, très compressé:\n\nEntre 5 et 20 fois plus léger qu’un CSV\nPas de perte d’efficacité en lecture\n\n\n\n\n\n\n\n\n\n\nExemple: recensement de la population\n\n\n\n20 millions de lignes, 88 colonnes\n\nCSV: &gt; 5Go\nParquet: 508Mo\n\n\n\n\n\n\n\n\n\n\n\n\nExemple: statistiques de la délinquance\n\n\n\n3.5 millions de lignes:\n\nCSV: 400Mo\nParquet: 11Mo"
  },
  {
    "objectID": "slides/index.html#le-csv-en-apparence-pratique",
    "href": "slides/index.html#le-csv-en-apparence-pratique",
    "title": "Le format de données Parquet",
    "section": "Le CSV: en apparence pratique",
    "text": "Le CSV: en apparence pratique\n\n\n\n\nFacile à lire, facile à ouvrir, mais\n\n\n\n\n\n\n\n\n\n\nProblème: il faut scanner tout le fichier pour avoir une seule colonne\n\n\n\nLent en lecture, pas compressé\nProblème pour deviner le type d’une variable\nMême si on ne veut que certaines colonnes, il faut lire tout le fichier"
  },
  {
    "objectID": "slides/index.html#parquet-un-format-orienté-colonne",
    "href": "slides/index.html#parquet-un-format-orienté-colonne",
    "title": "Le format de données Parquet",
    "section": "Parquet: un format orienté colonne",
    "text": "Parquet: un format orienté colonne\n\n\nPlus pratique pour n’ouvrir qu’un sous-ensemble de variables ;\n\nPas besoin de scanner tout le fichier pour étudier quelques variables ;"
  },
  {
    "objectID": "slides/index.html#parquet-quels-avantages",
    "href": "slides/index.html#parquet-quels-avantages",
    "title": "Le format de données Parquet",
    "section": "Parquet : quels avantages ?",
    "text": "Parquet : quels avantages ?\n\n\nFormat libre, open source, et indépendant du langage ;\n\n\n\nPlus de confort pour les utilisateurs:\n\nDes requêtes plus rapides et efficaces (seulement les données nécessaires sont lues)\nDes données conformes à la mise à disposition par le producteur (plus de problème de codes communes…)"
  },
  {
    "objectID": "slides/index.html#parquet-quels-usages",
    "href": "slides/index.html#parquet-quels-usages",
    "title": "Le format de données Parquet",
    "section": "Parquet : quels usages ?",
    "text": "Parquet : quels usages ?\n\nFormat privilégié pour la mise à disposition de données internes à l’Insee:\n\nMoins d’asymétries entre utilisateurs et producteurs.\n\n\n\n\n\n\n\n\nPremières diffusions à l’externe\n\n\n\nBureaux de votes du répertoire électoral unique (REU):\nRecensement de la population (RP)\nPlus récemment, la base permanente des équipements (BPE)"
  },
  {
    "objectID": "slides/index.html#parquet-quels-usages-1",
    "href": "slides/index.html#parquet-quels-usages-1",
    "title": "Le format de données Parquet",
    "section": "Parquet : quels usages ?",
    "text": "Parquet : quels usages ?\n\nviewof source = Inputs.radio([\n  \"Recensement\", \"Répertoire électoral unique\"\n], {value: \"Recensement\"})\n\n\n\n\n\n\n\n\nInputs.table(data)\n\n\n\n\n\n\n\ndata = (source == \"Recensement\") ? rp : reu\n\n\n\n\n\n\n\ndb = DuckDBClient.of({})\n\nrp = db.query(\n  \"SELECT AGED, CATL, SEXE, CANTVILLE, IPONDI FROM read_parquet('https://static.data.gouv.fr/resources/recensement-de-la-population-fichiers-detail-individus-localises-au-canton-ou-ville-2020-1/20231023-122841/fd-indcvi-2020.parquet') LIMIT 5\"\n)\nreu = db.query(\n  \"SELECT geo_adresse, id_brut_bv_reu FROM read_parquet('https://static.data.gouv.fr/resources/bureaux-de-vote-et-adresses-de-leurs-electeurs/20230626-135723/table-adresses-reu.parquet') LIMIT 5\"\n)"
  },
  {
    "objectID": "slides/index.html#pourquoi-duckdb",
    "href": "slides/index.html#pourquoi-duckdb",
    "title": "Le format de données Parquet",
    "section": "Pourquoi DuckDB ?",
    "text": "Pourquoi DuckDB ?\n\nParquet ne résout pas tout:\n\nL’espace disque est optimisé\nLes données décompressées doivent passer en RAM\n\n\n❓️ Comment analyser ces données sur un PC avec 8 GB de RAM ?"
  },
  {
    "objectID": "slides/index.html#pourquoi-duckdb-1",
    "href": "slides/index.html#pourquoi-duckdb-1",
    "title": "Le format de données Parquet",
    "section": "Pourquoi DuckDB ?",
    "text": "Pourquoi DuckDB ?"
  },
  {
    "objectID": "slides/index.html#pourquoi-duckdb-2",
    "href": "slides/index.html#pourquoi-duckdb-2",
    "title": "Le format de données Parquet",
    "section": "Pourquoi DuckDB ?",
    "text": "Pourquoi DuckDB ?\n\n\n\nDuckDB est un utilitaire open source\n\nUn logiciel en ligne de commande tout simple (20Mo)…\nDes librairies ,  et Observable pour simplifier l’usage\nRequêtes SQL mais aussi intégration tidyverse pour \n\n\n\n\n\n\n\n\n\nDuckDB est très efficace:\n\nMoteur SQL enrichi avec des fonctions très pratiques pour l’analyse\nOptimisations automatiques\nVisualisations sans exécuter sur toute la base\n\n\n\n\n💡 Les avantages du monde des bases de données sans ses inconvénients"
  },
  {
    "objectID": "slides/index.html#reproductibilité-des-exemples",
    "href": "slides/index.html#reproductibilité-des-exemples",
    "title": "Le format de données Parquet",
    "section": "Reproductibilité des exemples",
    "text": "Reproductibilité des exemples\n\n\n\nPlateforme de data science développée par l’Insee\n\nEnvironnements standardisés , \nAccessible aux chercheurs.euses pour l’enseignement 😉\n\n\n\n\nEnvironnements préconfigurés lançables en 1 clic:\n\n\n\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\nSi vous avez un compte, n’hésitez pas à essayer les exemples présentés en live !"
  },
  {
    "objectID": "slides/index.html#idées",
    "href": "slides/index.html#idées",
    "title": "Le format de données Parquet",
    "section": "Idées",
    "text": "Idées\n\nTuto ssphub\nFaire une carte des résidences secondaires en France\nModes de transport\nDistribution par âge\n\n\n\n\nAtelier tuto@mate (retour à la page principale de ce site)"
  },
  {
    "objectID": "tuto/observablehq.html",
    "href": "tuto/observablehq.html",
    "title": "Utilisation du format Parquet avec Observable illustré à partir de quelques exemples",
    "section": "",
    "text": "Page observablehq"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Atelier tuto@mate sur le format Parquet",
    "section": "",
    "text": "Un ensemble de ressources pour présenter les enjeux de l’utilisation du format Parquet illustré à partir des données du recensement.\n\n\n\n\n\n\n\n\n\n\nLe format de données Parquet\n\n\nSlides présentant les enjeux de l’utilisation du format Parquet et l’écosystème associé\n\n\n\nLino Galiana\n\n\nNov 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUtilisation du format Parquet avec  illustré à partir de quelques exemples\n\n\nTutoriel R\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUtilisation du format Parquet avec Python illustré à partir de quelques exemples\n\n\nTutoriel Python\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUtilisation du format Parquet avec Observable illustré à partir de quelques exemples\n\n\nTutoriel Observable\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\nNo matching items\n\n\nReplay de la présentation:"
  },
  {
    "objectID": "tuto/python.html",
    "href": "tuto/python.html",
    "title": "Utilisation du format Parquet avec Python illustré à partir de quelques exemples",
    "section": "",
    "text": "Ce tutoriel n’est pas encore fini, il sera progressivement enrichi\nCe tutoriel vise à offrir une approche complémentaire au guide d’utilisation des données du recensement au format Parquet publié sur https://ssphub.netlify.app pour accompagner la diffusion de celles-ci par l’Insee.\nIl s’agit d’un tutoriel préparé pour l’atelier tuto@mate à l’EHESS le 5 novembre 2024. Ce tutoriel est exclusivement en R. Les slides de la présentation sont disponibles ci-dessous:\nDérouler les slides ci-dessous ou cliquer ici pour afficher les slides en plein écran.\nIl propose des exemples variés pour illustrer la simplicité d’usage du format Parquet. Parmi ceux-ci, à partir du recensement de la population:"
  },
  {
    "objectID": "tuto/python.html#requêtes-sur-les-colonnes-select",
    "href": "tuto/python.html#requêtes-sur-les-colonnes-select",
    "title": "Utilisation du format Parquet avec Python illustré à partir de quelques exemples",
    "section": "Requêtes sur les colonnes (SELECT)",
    "text": "Requêtes sur les colonnes (SELECT)\nL’une des forces du format Parquet est de simplifier l’import de fichiers volumineux qui ne comportent que quelques colonnes nous intéressant. Par exemple, la table des individus comporte 88 colonnes, il est peu probable qu’une seule analyse s’intéresse à toutes celles-ci (ou elle risque d’être fort indigeste).\n\nComme cela est illustré dans ?@tip-optimisation-duckdb, la différence de volumétrie entre un fichier non filtré et un fichier filtré est importante.\n\nquery = (\n  f\"FROM read_parquet(\\\"{filename_table_individu}\\\") \"\n  \"SELECT IPONDI AS poids, AGED, VOIT \"\n  \"LIMIT 10\"\n)\nduckdb.sql(query).to_df()\n\n\n\n\n\n\n\n\npoids\nAGED\nVOIT\n\n\n\n\n0\n0.865066\n74\n0\n\n\n1\n4.987931\n39\n1\n\n\n2\n4.987931\n9\n1\n\n\n3\n5.013547\n55\n2\n\n\n4\n3.478368\n1\n0\n\n\n5\n3.478368\n43\n0\n\n\n6\n3.478368\n38\n0\n\n\n7\n1.003585\n46\n1\n\n\n8\n1.003585\n16\n1\n\n\n9\n0.984087\n59\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\nComprendre l’optimisation permise par Parquet et DuckDB\n\n\n\n\n\nPour réduire la volumétrie des données importées, il est possible de mettre en oeuvre deux stratégies:\n\nN’importer qu’un nombre limité de colonnes\nN’importer qu’un nombre limité de lignes\n\nComme cela a été évoqué dans les slides, le format Parquet est particulièrement optimisé pour le premier besoin. C’est donc généralement la première optimisation mise en oeuvre. Pour s’en convaincre on peut regarder la taille des données importées dans deux cas:\n\nOn utilise beaucoup de lignes mais peu de colonnes\nOn utilise beaucoup de colonnes mais peu de lignes\n\nPour cela, nous utilisons la fonction SQL EXPLAIN ANALYZE disponible dans duckdb. Elle décompose le plan d’exécution de duckdb, ce qui nous permettra de comprendre la stratégie d’optimisation. Elle permet aussi de connaître le volume de données importées lorsqu’on récupère un fichier d’internet. En effet, duckdb est malin: plutôt que de télécharger un fichier entier pour n’en lire qu’une partie, la librairie est capable de n’importer que les blocs du fichier qui l’intéresse.\nCeci nécessite l’utilisation de l’extension httpfs (un peu l’équivalent des library de R en duckdb). Elle s’installe et s’utilise de la manière suivante\n\nduckdb.sql(\"INSTALL httpfs; LOAD httpfs;\")\n\nDemandons à DuckDB d’exécuter la requête “beaucoup de colonnes, pas beaucoup de lignes” et regardons le plan d’exécution et les informations données par DuckDB:\n\n\nVoir le plan : “beaucoup de colonnes, pas beaucoup de lignes”\n\n\nurl_bpe = files_to_download.get(\"table_bpe\").get(\"url\")\n\nplan = duckdb.query(\nf\"\"\"\nEXPLAIN ANALYZE\nFROM read_parquet(\"{url_bpe}\")\nSELECT *\nLIMIT 5\n\"\"\"\n) \n\n\nprint(\n  plan.to_df()['explain_value'].iloc[0]\n)\n\n┌─────────────────────────────────────┐\n│┌───────────────────────────────────┐│\n││    Query Profiling Information    ││\n│└───────────────────────────────────┘│\n└─────────────────────────────────────┘\n EXPLAIN ANALYZE FROM read_parquet(\"https://minio.lab.sspcloud.fr/lgaliana/diffusion/BPE23.parquet\") SELECT * LIMIT 5 \n┌─────────────────────────────────────┐\n│┌───────────────────────────────────┐│\n││         HTTPFS HTTP Stats         ││\n││                                   ││\n││            in: 60.2 MiB           ││\n││            out: 0 bytes           ││\n││              #HEAD: 1             ││\n││              #GET: 3              ││\n││              #PUT: 0              ││\n││              #POST: 0             ││\n│└───────────────────────────────────┘│\n└─────────────────────────────────────┘\n┌────────────────────────────────────────────────┐\n│┌──────────────────────────────────────────────┐│\n││              Total Time: 10.87s              ││\n│└──────────────────────────────────────────────┘│\n└────────────────────────────────────────────────┘\n┌───────────────────────────┐\n│           QUERY           │\n└─────────────┬─────────────┘\n┌─────────────┴─────────────┐\n│      EXPLAIN_ANALYZE      │\n│    ────────────────────   │\n│           0 Rows          │\n│          (0.00s)          │\n└─────────────┬─────────────┘\n┌─────────────┴─────────────┐\n│      STREAMING_LIMIT      │\n│    ────────────────────   │\n│           5 Rows          │\n│          (0.00s)          │\n└─────────────┬─────────────┘\n┌─────────────┴─────────────┐\n│         TABLE_SCAN        │\n│    ────────────────────   │\n│         Function:         │\n│        READ_PARQUET       │\n│                           │\n│        Projections:       │\n│             AN            │\n│           NOMRS           │\n│           CNOMRS          │\n│          NUMVOIE          │\n│           INDREP          │\n│          TYPVOIE          │\n│          LIBVOIE          │\n│            CADR           │\n│           CODPOS          │\n│           DEPCOM          │\n│            DEP            │\n│            REG            │\n│            DOM            │\n│            SDOM           │\n│           TYPEQU          │\n│           SIRET           │\n│      STATUT_DIFFUSION     │\n│          CANTINE          │\n│          INTERNAT         │\n│            RPI            │\n│             EP            │\n│           CL_PGE          │\n│            SECT           │\n│    ACCES_AIRE_PRATIQUE    │\n│        ACCES_LIBRE        │\n└───────────────────────────┘\n\n\n\n\n\n\nVoir le plan : “pas de colonnes, beaucoup de lignes”\n\n\nplan = duckdb.sql(\n  f\"\"\"\n  EXPLAIN ANALYZE\n  SELECT TYPEQU, LONGITUDE, LATITUDE FROM read_parquet(\"{url_bpe}\") LIMIT 10000\n  \"\"\"\n)\n\n\nprint(\n  plan.to_df()['explain_value'].iloc[0]\n)\n\n┌─────────────────────────────────────┐\n│┌───────────────────────────────────┐│\n││    Query Profiling Information    ││\n│└───────────────────────────────────┘│\n└─────────────────────────────────────┘\n   EXPLAIN ANALYZE   SELECT TYPEQU, LONGITUDE, LATITUDE FROM read_parquet(\"https://minio.lab.sspcloud.fr/lgaliana/diffusion/BPE23.parquet\") LIMIT 10000   \n┌─────────────────────────────────────┐\n│┌───────────────────────────────────┐│\n││         HTTPFS HTTP Stats         ││\n││                                   ││\n││            in: 13.8 MiB           ││\n││            out: 0 bytes           ││\n││              #HEAD: 1             ││\n││              #GET: 4              ││\n││              #PUT: 0              ││\n││              #POST: 0             ││\n│└───────────────────────────────────┘│\n└─────────────────────────────────────┘\n┌────────────────────────────────────────────────┐\n│┌──────────────────────────────────────────────┐│\n││               Total Time: 1.55s              ││\n│└──────────────────────────────────────────────┘│\n└────────────────────────────────────────────────┘\n┌───────────────────────────┐\n│           QUERY           │\n└─────────────┬─────────────┘\n┌─────────────┴─────────────┐\n│      EXPLAIN_ANALYZE      │\n│    ────────────────────   │\n│           0 Rows          │\n│          (0.00s)          │\n└─────────────┬─────────────┘\n┌─────────────┴─────────────┐\n│      STREAMING_LIMIT      │\n│    ────────────────────   │\n│         10000 Rows        │\n│          (0.00s)          │\n└─────────────┬─────────────┘\n┌─────────────┴─────────────┐\n│         TABLE_SCAN        │\n│    ────────────────────   │\n│         Function:         │\n│        READ_PARQUET       │\n│                           │\n│        Projections:       │\n│           TYPEQU          │\n│         LONGITUDE         │\n│          LATITUDE         │\n│                           │\n│         12288 Rows        │\n│          (1.55s)          │\n└───────────────────────────┘\n\n\n\n\nLa comparaison de ces plans d’exécution montre l’intérêt de faire un filtre sur les colonnes : les besoins computationnels sont drastiquement diminués. Le filtre sur les lignes n’arrive que dans un second temps, une fois les colonnes sélectionnées.\nPourquoi seulement un rapport de 1 à 4 entre le poids des deux fichiers ? C’est parce que nos requêtes comportent toute deux la variable IPONDI (les poids à utiliser pour extrapoler l’échantillon à la population) qui est à haute précision là où beaucoup d’autres colonnes comportent un nombre réduit de modalités et sont donc peu volumineuses.\n\n\n\nDuckDB propose également des fonctionnalités pour extraire des colonnes à travers des expressions régulières. Cette approche est également possible avec le tidyverse\n\nduckdb.sql(\n  f\"\"\"\n    FROM read_parquet(\\\"{filename_table_individu}\\\")\n    SELECT IPONDI AS poids, COLUMNS('.*AGE.*')\n    LIMIT 10\n  \"\"\"\n).to_df()\n\n\n\n\n\n\n\n\npoids\nAGED\nAGER20\nAGEREV\nAGEREVQ\n\n\n\n\n0\n0.865066\n74\n79\n73\n70\n\n\n1\n4.987931\n39\n39\n38\n35\n\n\n2\n4.987931\n9\n10\n8\n5\n\n\n3\n5.013547\n55\n54\n54\n50\n\n\n4\n3.478368\n1\n2\n0\n0\n\n\n5\n3.478368\n43\n54\n42\n40\n\n\n6\n3.478368\n38\n39\n37\n35\n\n\n7\n1.003585\n46\n54\n45\n45\n\n\n8\n1.003585\n16\n17\n15\n15\n\n\n9\n0.984087\n59\n64\n58\n55"
  },
  {
    "objectID": "tuto/python.html#requêtes-sur-les-lignes-where",
    "href": "tuto/python.html#requêtes-sur-les-lignes-where",
    "title": "Utilisation du format Parquet avec Python illustré à partir de quelques exemples",
    "section": "Requêtes sur les lignes (WHERE)",
    "text": "Requêtes sur les lignes (WHERE)\n\nduckdb.sql(\n    f\"\"\"\n    FROM read_parquet(\"{filename_table_individu}\")\n    SELECT IPONDI, AGED, DEPT\n    WHERE DEPT IN ('11', '31', '34')\n    LIMIT 10\n    \"\"\"\n).to_df()\n\n\n\n\n\n\n\n\nIPONDI\nAGED\nDEPT\n\n\n\n\n0\n5.027778\n59\n11\n\n\n1\n5.027778\n83\n11\n\n\n2\n4.996593\n50\n11\n\n\n3\n4.996593\n26\n11\n\n\n4\n5.148676\n9\n11\n\n\n5\n5.148676\n38\n11\n\n\n6\n5.148676\n49\n11\n\n\n7\n5.000000\n88\n11\n\n\n8\n5.000000\n88\n11\n\n\n9\n5.297153\n18\n11\n\n\n\n\n\n\n\nLes filtres sur les observations peuvent être faits à partir de critères sur plusieurs colonnes. Par exemple, pour ne conserver que les observations de la ville de Nice où la date d’emménagement est postérieure à 2020, la requête suivante peut être utilisée :\n\nduckdb.sql(\n    f\"\"\"\n    FROM read_parquet(\"{filename_table_logement}\")\n    SELECT *\n    WHERE COMMUNE = '06088' AND AEMM &gt; 2020\n    LIMIT 10\n    \"\"\"\n).to_df()\n\n\n\n\n\n\n\n\nCOMMUNE\nARM\nIRIS\nACHL\nAEMM\nAEMMR\nAGEMEN8\nANEM\nANEMR\nASCEN\n...\nSTOCD\nSURF\nTACTM\nTPM\nTRANSM\nTRIRIS\nTYPC\nTYPL\nVOIT\nWC\n\n\n\n\n0\n06088\nZZZZZ\n060880101\nA11\n2022\n9\n40\n0\n0\n2\n...\n21\n4\n11\n1\n5\n060421\n3\n2\n1\nZ\n\n\n1\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n40\n1\n0\n2\n...\n10\n2\n11\n1\n6\n060421\n3\n2\n0\nZ\n\n\n2\n06088\nZZZZZ\n060880101\nA12\n2021\n9\n25\n1\n0\n2\n...\n21\n2\n12\nZ\nZ\n060421\n3\n2\n0\nZ\n\n\n3\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n40\n1\n0\n2\n...\n21\n3\n11\n1\n5\n060421\n3\n2\n1\nZ\n\n\n4\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n40\n1\n0\n2\n...\n21\n3\n11\n1\n5\n060421\n3\n2\n1\nZ\n\n\n5\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n40\n1\n0\n2\n...\n21\n2\n11\n1\n2\n060421\n3\n2\n0\nZ\n\n\n6\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n25\n1\n0\n2\n...\n21\n2\n11\n1\n2\n060421\n2\n2\n0\nZ\n\n\n7\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n40\n1\n0\n2\n...\n21\n2\n11\n1\n2\n060421\n3\n2\n0\nZ\n\n\n8\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n25\n1\n0\n2\n...\n21\n5\n11\n1\n6\n060421\n3\n2\n1\nZ\n\n\n9\n06088\nZZZZZ\n060880101\nA11\n2021\n9\n55\n1\n0\n2\n...\n21\n3\n12\nZ\nZ\n060421\n2\n2\n0\nZ\n\n\n\n\n10 rows × 69 columns"
  },
  {
    "objectID": "tuto/python.html#exemples-sans-groupes",
    "href": "tuto/python.html#exemples-sans-groupes",
    "title": "Utilisation du format Parquet avec Python illustré à partir de quelques exemples",
    "section": "Exemples sans groupes",
    "text": "Exemples sans groupes\nLa fonction DISTINCT appliquée à la variable ARM permet d’extraire la liste des codes arrondissements présents dans la base de données.\n\nquery = f\"\"\"\nFROM read_parquet('{filename_table_logement}')\nSELECT DISTINCT ARM\nWHERE NOT ARM LIKE '%ZZZZZ%'\nORDER BY ARM\n\"\"\"\n\nresult = \", \".join(duckdb.sql(query).to_df()[\"ARM\"])\n\nIl est possible d’extraire des statistiques beaucoup plus raffinées par le biais d’une requête SQL plus complexe. Par exemple pour calculer le nombre d’habitants de Toulouse qui ont changé de logement en un an:\n\nquery = f\"\"\"\nFROM read_parquet(\"{filename_table_logement}\")\nSELECT CAST(SUM(IPONDL * CAST(INPER AS INT)) AS INT) \nAS habitants_toulouse_demenagement\nWHERE COMMUNE = '31555' \nAND IRANM NOT IN ('1', 'Z') \nAND INPER != 'Y'\n\"\"\"\n\nduckdb.sql(query).to_df()\n\n\n\n\n\n\n\n\nhabitants_toulouse_demenagement\n\n\n\n\n0\n86364"
  },
  {
    "objectID": "tuto/python.html#statistiques-par-groupe",
    "href": "tuto/python.html#statistiques-par-groupe",
    "title": "Utilisation du format Parquet avec Python illustré à partir de quelques exemples",
    "section": "Statistiques par groupe",
    "text": "Statistiques par groupe\nSQL et dplyr permettent d’aller loin dans la finesse des statistiques descriptives mises en oeuvre. Cela sera illustré à l’aide de plusieurs exemples réflétant des statistiques pouvant être construites grâce à ces données détaillées.\n\nExemple 1: pyramide des âges dans l’Aude, l’Hérault et le Gard\nLe premier exemple est un comptage sur trois départements. Il illustre la démarche suivante:\n\nOn se restreint aux observations d’intérêt (ici 3 départements)\nOn applique la fonction summarise pour calculer une statistique par groupe, en l’occurrence la somme des pondérations\nOn retravaille les données\n\nEnsuite, une fois que nos données sont récupérées dans R, on peut faire la figure avec ggplot\n\n\n\n\nListing 1: Pyramide des âges dans l’Aude, l’Hérault et le Gard\n\n\npyramide_ages = duckdb.sql(\n        f\"\"\"\n        FROM read_parquet(\"{filename_table_individu}\")\n        SELECT AGED, DEPT AS departement, SUM(IPONDI) AS individus\n        WHERE DEPT IN ('11', '31', '34')\n        GROUP BY AGED, DEPT\n        ORDER BY DEPT, AGED\n        \"\"\"\n    ).to_df()\n\n# Create the plot\nplot = (\n    ggplot(pyramide_ages, aes(x='AGED', y='individus'))\n    + geom_bar(aes(fill='departement'), stat=\"identity\")\n    + geom_vline(xintercept=18, color=\"grey\", linetype=\"dashed\")\n    + facet_wrap('~departement', scales=\"free_y\", nrow=3)\n    + theme_minimal()\n    + labs(y=\"Individus recensés\", x=\"Âge\")\n)\n\nplot\n\n\n\n\n\n\n\n\n\n\n\n\n\nExemple 2: répartition des plus de 60 ans par département\nL’objectif de ce deuxième exemple est d’illustrer la construction d’une statistique un peu plus complexe et la manière de projeter celle-ci sur une carte.\nPour avoir la répartition des plus de 60 ans par département, quelques lignes de dplyr suffisent:\n\nimport pandas as pd\nimport duckdb\n\n# Query to calculate total population and population over 60\npart_population_60_plus = duckdb.sql(\n    f\"\"\"\n    FROM read_parquet(\"{filename_table_individu}\")\n    SELECT \n        DEPT,\n        SUM(IPONDI) AS total_population,\n        SUM(CASE WHEN AGED &gt; 60 THEN IPONDI ELSE 0 END) AS population_60_plus\n    GROUP BY DEPT\n    \"\"\"\n).to_df()\n\n# Calculate percentage of population over 60\npart_population_60_plus['pourcentage_60_plus'] = (\n    part_population_60_plus['population_60_plus'] / part_population_60_plus['total_population'] * 100\n)\n\n# Display the result\npart_population_60_plus\n\n\n\n\n\n\n\n\nDEPT\ntotal_population\npopulation_60_plus\npourcentage_60_plus\n\n\n\n\n0\n52\n1.719665e+05\n55585.299808\n32.323331\n\n\n1\n53\n3.065790e+05\n87148.948812\n28.426262\n\n\n2\n64\n6.871390e+05\n213963.219260\n31.138274\n\n\n3\n65\n2.295735e+05\n79045.428197\n34.431426\n\n\n4\n85\n6.925099e+05\n219234.728530\n31.657991\n\n\n...\n...\n...\n...\n...\n\n\n95\n2A\n1.607982e+05\n49182.373626\n30.586396\n\n\n96\n70\n2.344830e+05\n70894.963917\n30.234591\n\n\n97\n71\n5.511182e+05\n181998.102753\n33.023424\n\n\n98\n73\n4.394649e+05\n120145.543592\n27.339052\n\n\n99\n77\n1.428738e+06\n287073.307178\n20.092786\n\n\n\n\n100 rows × 4 columns\n\n\n\nIl ne reste plus qu’à projeter ceci sur une carte. Pour cela, un join à notre fond de carte suffit. Comme les données sont agrégées et déjà dans R, il n’y a rien de spécifique à duckdb ici.\n\n\nAssociation de part_population_60_plus au fond de carte des départements\n# Joindre les données au fond de carte des départements\n\ndepartements_60_plus_gpd = (\n  departements\n    .merge(\n      part_population_60_plus,\n      left_on = \"INSEE_DEP\",\n      right_on = \"DEPT\"\n    )\n)\n\n\nFinalement, il ne reste plus qu’à produire la carte:\n\ndepartements_60_plus_gpd['pourcentage_60_plus_d'] = pd.qcut(\n  departements_60_plus_gpd['pourcentage_60_plus'],\n  q=4\n)\n\n\n(\n  ggplot(departements_60_plus_gpd) +\n    geom_map(aes(fill = \"pourcentage_60_plus_d\")) + \n    scale_fill_brewer(palette = \"PuBuGn\", direction = 1) + \n    theme_void() + \n    labs(\n        title = \"Part des personnes de plus de 60 ans par département\",\n        caption = \"Source: Insee, Fichiers détails du recensement de la population\",\n        fill = \"Part (%)\"\n    )\n)\n\n\n\n\n\n\n\n\nSi on préfère représenter ceci sous forme de tableau, on peut utiliser le package great tables. Cela nécessite quelques manipulations de données en amont.\n\npart_population_60_plus_dep = part_population_60_plus.merge(\n  departements.loc[:, [\"INSEE_DEP\", \"LIBELLE_DEPARTEMENT\"]],\n  left_on = \"DEPT\",\n  right_on = \"INSEE_DEP\"\n)\npart_population_60_plus_dep[\"departement\"] = part_population_60_plus_dep[\"LIBELLE_DEPARTEMENT\"] + \" (\" + part_population_60_plus_dep[\"DEPT\"]  + \")\"\n\npart_population_60_plus_dep = part_population_60_plus_dep.sort_values(\"pourcentage_60_plus\", ascending=False).head(10)\n\n\nfrom great_tables import *\n(\n  GT(\n    part_population_60_plus_dep.loc[\n      :, ['departement', 'total_population', 'population_60_plus', 'pourcentage_60_plus']\n    ]\n  )\n  .fmt_number(columns=[\n    \"total_population\", \"population_60_plus\"\n  ], compact=True)\n  .fmt_percent(\"pourcentage_60_plus\", scale_values = False)\n  .fmt_nanoplot(columns=\"pourcentage_60_plus\", plot_type=\"bar\")\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\ndepartement\ntotal_population\npopulation_60_plus\npourcentage_60_plus\n\n\n\n\nCreuse (23)\n116.18K\n45.56K\n\n\n\n\n39.2\n\n\n\n\nLot (46)\n174.40K\n67.12K\n\n\n\n\n38.5\n\n\n\n\nNièvre (58)\n202.73K\n76.11K\n\n\n\n\n37.5\n\n\n\n\nDordogne (24)\n413.18K\n153.40K\n\n\n\n\n37.1\n\n\n\n\nCantal (15)\n144.32K\n51.59K\n\n\n\n\n35.7\n\n\n\n\nGers (32)\n191.74K\n68.26K\n\n\n\n\n35.6\n\n\n\n\nIndre (36)\n218.47K\n77.54K\n\n\n\n\n35.5\n\n\n\n\nCharente-Maritime (17)\n655.65K\n232.01K\n\n\n\n\n35.4\n\n\n\n\nAllier (03)\n335.38K\n118.48K\n\n\n\n\n35.3\n\n\n\n\nCorrèze (19)\n239.29K\n84.51K\n\n\n\n\n35.3\n\n\n\n\n\n\n\n\n        \n\n\n\n\nExemple 3: part des résidences secondaires et des logements vacants\nIl est tout à fait possible de faire des étapes antérieures de préparation de données, notamment de création de variables avec mutate.\nL’exemple suivant illustre la préparation de données avant la construction de statistiques descriptives de la manière suivante:\n\nCréation d’une variable de département à partir du code commune\nDécompte des logements par département\n\nSuite du tutoriel à venir\n\nimport shutil\nshutil.rmtree(\"data\")"
  },
  {
    "objectID": "tuto/python.html#footnotes",
    "href": "tuto/python.html#footnotes",
    "title": "Utilisation du format Parquet avec Python illustré à partir de quelques exemples",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPour en savoir plus sur ce projet, se rendre sur la documentation du projet.↩︎"
  }
]